{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSwjNBAkCDPfLvjX77GdpZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pfolaa/dsti-labs/blob/main/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfrluZHFeoJi",
        "outputId": "8ad89b70-863c-42e0-deb4-2c318f29bb9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDZLS2SVpWRA"
      },
      "source": [
        "import os\n",
        "import glob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXUmQBdjjRSz"
      },
      "source": [
        "#cd /content/drive/MyDrive/datasets/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A647jZGTIVfV"
      },
      "source": [
        "## 1- Data acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM0BTYUsH0J7"
      },
      "source": [
        "###1.1- Get files from repository "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2XWYG1djOng"
      },
      "source": [
        "#!wget https://{bucket-name}.s3.eu-west-1.amazonaws.com/{file.zip}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ePlT65iHvE8"
      },
      "source": [
        "### 1.2 Extract zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY4poFTe_fiZ"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "#ZipFile(\"{file.zip}\").extractall('/content/drive/My Drive/datasets/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Bife_AHmwn"
      },
      "source": [
        "### 1.3 Read all json files and insert into a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9kYyZKupaKF"
      },
      "source": [
        "import os,json\n",
        "import pandas as pd\n",
        "\n",
        "# read json file\n",
        "def read_Json_And_Insert_Into_CSV(path_file_json, file_csv, root_path):\n",
        "  os.makedirs(root_path, exist_ok=True) # créer toute l'aborescence du fichier, crée le chemin\n",
        "  # read all json files\n",
        "  for file_name in [file for file in os.listdir(path_file_json) if file.endswith('.json')]:\n",
        "    with open(path_file_json + file_name) as json_file:\n",
        "      data = json.load(json_file)\n",
        "      df = pd.DataFrame.from_records(data)\n",
        "\n",
        "  # convert file to csv\n",
        "  df.to_csv(f'{root_path}/{file_csv}', sep=';')\n",
        "  return df # return du fichier csv"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIL79akW0R8f"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9HdEw7t0Sjx"
      },
      "source": [
        "###NB: ne pas utiliser les memes noms de variables à l'intérieur des fonctions et à l'extérieur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCh5277VyUV4"
      },
      "source": [
        "path_json = '/content/drive/My Drive/datasets/nirra-log-bot/'\n",
        "root_csv = '/content/drive/My Drive/datasets/nirra-log-bot/csv'\n",
        "file_csv = 'file_name.csv'\n",
        "\n",
        "df_raw = read_Json_And_Insert_Into_CSV(path_json, file_csv, root_csv)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4q9nXruZEeS"
      },
      "source": [
        "df_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5hLbakIA9g"
      },
      "source": [
        "### Get total number of @ inside \"text\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1tAb3ZqNXxk",
        "outputId": "b2c4d93a-d9fc-4f7a-f5df-9c9f296ee873"
      },
      "source": [
        " df_raw['text'].str.contains(\"@\").sum() # search total number of @ within text column"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h6pXkQwHaf_"
      },
      "source": [
        "### Test a slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOYCDMimN7Os"
      },
      "source": [
        "# slicing\n",
        "#df_raw[df_raw['text'].str.contains(\"@\")] # masque à l'intérieur des crochets"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7TN5BDtoPudJ",
        "outputId": "e2fce524-d77f-4923-ea0d-6cd20732dc7f"
      },
      "source": [
        "df_raw[df_raw['text'] == None]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>subtype</th>\n",
              "      <th>text</th>\n",
              "      <th>ts</th>\n",
              "      <th>bot_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [type, subtype, text, ts, bot_id]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGScI9DACyVX"
      },
      "source": [
        "### Functions used in case of OKRA WEBHOOK, WALLET SUCCESS, SMS SUCCESS, SMS PAYLOAD Types request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CapeBj_Wqfkd"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "#text_okra_webhook = df_raw['text'][0]\n",
        "#text_wallet = df_raw['text'][841]\n",
        "#sms_success = df_raw['text'][12]\n",
        "#sms_payload = df_raw['text'][11]\n",
        "def parse_wallet_sms_payload_success(text_type_request):\n",
        "  ''' la fonction permet de parser les types de requete \"Okra WebHook\", \"Wallet success\", \n",
        "      \"SMS Success\" et SMS Payload en object json.\n",
        "      Elle prend en paramètre le text contenu dans le type de requete,\n",
        "      elle retourne un objet de type JSON.'''\n",
        "\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_type_request)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  s = json.loads(res)\n",
        "  out_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "\n",
        "  out_dump = json.dumps(out_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_wallet_success = json.loads(out_dump) # convertir le string json en object json.\n",
        "  return out_wallet_success\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f_3vBokI4W_"
      },
      "source": [
        "# Test Okra WebHook\n",
        "okra = parse_wallet_sms_payload_success(df_raw['text'][0])\n",
        "okra\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r42HQDd7IqD4"
      },
      "source": [
        "# Test Wallet Success\n",
        "wallet_success = parse_wallet_sms_payload_success(df_raw['text'][841])\n",
        "print(wallet_success.get('account_name'))\n",
        "print(wallet_success.get('account_number'))\n",
        "print(wallet_success.get('bvn'))\n",
        "print(wallet_success.get('requestSuccessful'))\n",
        "print(wallet_success.get('responseCode'))\n",
        "print(wallet_success.get('responseMessage'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vol_EjbkIdeu",
        "outputId": "50aa17a7-26ea-4e77-bbb5-1a8fc2e88e98"
      },
      "source": [
        "# Test SMS Sucess\n",
        "sms_succ = parse_wallet_sms_payload_success(df_raw['text'][12])\n",
        "sms_succ.get('response').get('cost ')\n",
        "sms_succ.get('response').get('status ')\n",
        "sms_succ.get('response').get('totalsent ')\n",
        "sms_succ.get('response')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost ': 2, 'status ': 'SUCCESS ', 'totalsent ': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIJQYyhvJfry"
      },
      "source": [
        "# Test SMS Payload\n",
        "sms_payload = parse_wallet_sms_payload_success(df_raw['text'][11])\n",
        "print(sms_payload)\n",
        "print(sms_payload.get('message'))\n",
        "print(sms_payload.get('phone'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxLQChIkYxVc"
      },
      "source": [
        "# Function to handle row with type request \"LEADWAY SUCCESS\" and concatenate rows\n",
        "### NB: faire un docstring (''' ''') pour chaque fonction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4c-G8ZBYp_Z"
      },
      "source": [
        "import re\n",
        "\n",
        "# la fonction doit prendre en paramètre quelque chose\n",
        "def parse_and_concatenate_Leadway_Success_Rows(df_raw):\n",
        "  '''Cette fonction permet de parser et de concatener le texte qui a LEADWAY SUCCESS\n",
        "     comme type de requete\n",
        "     elle prend comme paramètre un dataframe et retourne les valeurs suivantes:\n",
        "     - un texte concatené\n",
        "     - l'index de la 1ère ligne qu'on va utiliser ensuite pour l'effacer\n",
        "     - l'index de la dernière ligne qu'on va utiliser ensuite pour l'effacer '''\n",
        "\n",
        "  first_index = 0\n",
        "  last_index = 0\n",
        "  text_leadway_concat = ''\n",
        "  for index, row in df_raw.iterrows():  # boucler sur les colonnes de type text\n",
        "      text_row = row['text']  \n",
        "      if re.search('LEADWAY SUCCESS', text_row):\n",
        "        text_leadway_concat = text_row\n",
        "        first_index = index\n",
        "        first_index +=1\n",
        "        new_df = df_raw[first_index:]\n",
        "        for first_index, new_row in new_df.iterrows():\n",
        "          xxx = new_row['text']      \n",
        "          if not xxx.startswith('['):          \n",
        "            first_index += 1\n",
        "            text_leadway_concat = text_row + xxx       \n",
        "          elif xxx.startswith('['):\n",
        "            last_index = first_index-1\n",
        "            break\n",
        "\n",
        "\n",
        "  return text_leadway_concat, first_index, last_index\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfztKeA8XgQ"
      },
      "source": [
        "leadway_succ, first_index_succ, last_index_succ = parse_and_concatenate_Leadway_Success_Rows(df_raw)\n",
        "leadway_succ, first_index_succ, last_index_succ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mliPyobDr4k"
      },
      "source": [
        "### Function to parse row Leadway Success to json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2FJ1cmnDl0A"
      },
      "source": [
        "# use this function when type request is LEADWAY SUCCESS\n",
        "import regex\n",
        "import json\n",
        "\n",
        "\n",
        "def parse_Leadway_Success_Row(text_leadway):\n",
        "  ''' fonction permettant de parser le text concatené pour le type de requet LEADWAY SUCCESS\n",
        "      elle retourner un dictionnaire.'''\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_leadway)\n",
        "  resul_patt[0] = resul_patt[0].replace(\"\\\\\", \"\")\n",
        "  x = resul_patt[0].replace(\"make,\", \"\")\n",
        "  y = x.replace('\"\"makeName\"', '\"makeName\"')\n",
        "  z = json.loads(y)\n",
        "  vehicleMake = z.get('vehicleMake')\n",
        "  leadway_dict = {}\n",
        "  for element in vehicleMake:\n",
        "    leadway_dict[element['id']] = element['makeName']\n",
        "\n",
        "  return leadway_dict\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyu1DwSqdRrV",
        "outputId": "a8ac8cb7-82b0-440e-daf4-0e1683ca1741"
      },
      "source": [
        "print(leadway_succ)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] - [\"[LEADWAY SUCCESS]:\",\"{\\\"errorMsg\\\":\\\"\\\",\\\"signature\\\":\\\"\\\",\\\"success\\\":true,\\\"vehicleMake\\\":[{\\\"id\\\":\\\"127\\\",\\\"makeName\\\":\\\"35CMB\\\"},{\\\"id\\\":\\\"152\\\",\\\"makeName\\\":\\\"AC ATUL\\\"},{\\\"id\\\":\\\"228\\\",\\\"makeName\\\":\\\"ACE\\\"},{\\\"id\\\":\\\"147\\\",\\\"makeName\\\":\\\"ACURA\\\"},{\\\"id\\\":\\\"8\\\",\\\"makeName\\\":\\\"ALPHA ROMEO\\\"},{\\\"id\\\":\\\"106\\\",\\\"makeName\\\":\\\"APACHE\\\"},{\\\"id\\\":\\\"210\\\",\\\"makeName\\\":\\\"ASHOK LEYLAND\\\"},{\\\"id\\\":\\\"80\\\",\\\"makeName\\\":\\\"ASTRA\\\"},{\\\"id\\\":\\\"3\\\",\\\"makeName\\\":\\\"AUDI\\\"},{\\\"id\\\":\\\"128\\\",\\\"makeName\\\":\\\"AUSTIN\\\"},{\\\"id\\\":\\\"109\\\",\\\"makeName\\\":\\\"BACK HOE\\\"},{\\\"id\\\":\\\"9\\\",\\\"makeName\\\":\\\"BADFORD\\\"},{\\\"id\\\":\\\"68\\\",\\\"makeName\\\":\\\"BAJAJ\\\"},{\\\"id\\\":\\\"218\\\",\\\"makeName\\\":\\\"BASUKI\\\"},{\\\"id\\\":\\\"248\\\",\\\"makeName\\\":\\\"BAW\\\"},{\\\"id\\\":\\\"244\\\",\\\"makeName\\\":\\\"BEDFORD\\\"},{\\\"id\\\":\\\"84\\\",\\\"makeName\\\":\\\"BEIBEN\\\"},{\\\"id\\\":\\\"195\\\",\\\"makeName\\\":\\\"BELL\\\"},{\\\"id\\\":\\\"174\\\",\\\"makeName\\\":\\\"BENTLEY\\\"},{\\\"id\\\":\\\"75\\\",\\\"makeName\\\":\\\"BHACHU\\\"},{\\\"id\\\":\\\"262\\\",\\\"makeName\\\":\\\"BIKEMASTER\\\"},{\\\"id\\\":\\\"92\\\",\\\"makeName\\\":\\\"BLUE BIRD\\\"},{\\\"id\\\":\\\"7\\\",\\\"makeName\\\":\\\"BMW\\\"},{\\\"id\\\":\\\"10\\\",\\\"makeName\\\":\\\"BOBCAT\\\"},{\\\"id\\\":\\\"290\\\",\\\"makeName\\\":\\\"BOVA\\\"},{\\\"id\\\":\\\"126\\\",\\\"makeName\\\":\\\"BPW\\\"},{\\\"id\\\":\\\"269\\\",\\\"makeName\\\":\\\"BRILLIANCE\\\"},{\\\"id\\\":\\\"182\\\",\\\"makeName\\\":\\\"BUICK\\\"},{\\\"id\\\":\\\"11\\\",\\\"makeName\\\":\\\"CADILLAC\\\"},{\\\"id\\\":\\\"12\\\",\\\"makeName\\\":\\\"CAM\\\"},{\\\"id\\\":\\\"284\\\",\\\"makeName\\\":\\\"CANTER FUSO\\\"},{\\\"id\\\":\\\"89\\\",\\\"makeName\\\":\\\"CAPTAIN\\\"},{\\\"id\\\":\\\"217\\\",\\\"makeName\\\":\\\"CARTER PEN\\\"},{\\\"id\\\":\\\"13\\\",\\\"makeName\\\":\\\"CAT\\\"},{\\\"id\\\":\\\"239\\\",\\\"makeName\\\":\\\"CATERPILLAR\\\"},{\\\"id\\\":\\\"254\\\",\\\"makeName\\\":\\\"CHANA STAR\\\"},{\\\"id\\\":\\\"142\\\",\\\"makeName\\\":\\\"CHANGAN\\\"},{\\\"id\\\":\\\"223\\\",\\\"makeName\\\":\\\"CHANGFENG\\\"},{\\\"id\\\":\\\"141\\\",\\\"makeName\\\":\\\"CHERRY\\\"},{\\\"id\\\":\\\"283\\\",\\\"makeName\\\":\\\"CHERY\\\"},{\\\"id\\\":\\\"14\\\",\\\"makeName\\\":\\\"CHEVROLET\\\"},{\\\"id\\\":\\\"15\\\",\\\"makeName\\\":\\\"CHRYSLER\\\"},{\\\"id\\\":\\\"16\\\",\\\"makeName\\\":\\\"CITROEN\\\"},{\\\"id\\\":\\\"104\\\",\\\"makeName\\\":\\\"CLAAS\\\"},{\\\"id\\\":\\\"17\\\",\\\"makeName\\\":\\\"CMC\\\"},{\\\"id\\\":\\\"181\\\",\\\"makeName\\\":\\\"COMMER\\\"},{\\\"id\\\":\\\"129\\\",\\\"makeName\\\":\\\"CPCD\\\"},{\\\"id\\\":\\\"275\\\",\\\"makeName\\\":\\\"DACIA\\\"},{\\\"id\\\":\\\"18\\\",\\\"makeName\\\":\\\"DAEWOO\\\"},{\\\"id\\\":\\\"138\\\",\\\"makeName\\\":\\\"DAF\\\"},{\\\"id\\\":\\\"19\\\",\\\"makeName\\\":\\\"DAIHATSU\\\"},{\\\"id\\\":\\\"131\\\",\\\"makeName\\\":\\\"DALIAN\\\"},{\\\"id\\\":\\\"190\\\",\\\"makeName\\\":\\\"DATSUN\\\"},{\\\"id\\\":\\\"191\\\",\\\"makeName\\\":\\\"DAVE\\\"},{\\\"id\\\":\\\"161\\\",\\\"makeName\\\":\\\"DAYLONG\\\"},{\\\"id\\\":\\\"99\\\",\\\"makeName\\\":\\\"DAYUN\\\"},{\\\"id\\\":\\\"158\\\",\\\"makeName\\\":\\\"DEGAB\\\"},{\\\"id\\\":\\\"179\\\",\\\"makeName\\\":\\\"DENNIS\\\"},{\\\"id\\\":\\\"150\\\",\\\"makeName\\\":\\\"DENSTAR\\\"},{\\\"id\\\":\\\"216\\\",\\\"makeName\\\":\\\"DFAC\\\"},{\\\"id\\\":\\\"270\\\",\\\"makeName\\\":\\\"DFM\\\"},{\\\"id\\\":\\\"243\\\",\\\"makeName\\\":\\\"DIAMOND REO\\\"},{\\\"id\\\":\\\"183\\\",\\\"makeName\\\":\\\"DODGE\\\"},{\\\"id\\\":\\\"74\\\",\\\"makeName\\\":\\\"DOLL\\\"},{\\\"id\\\":\\\"88\\\",\\\"makeName\\\":\\\"DONGFENG\\\"},{\\\"id\\\":\\\"132\\\",\\\"makeName\\\":\\\"DOOSAN\\\"},{\\\"id\\\":\\\"20\\\",\\\"makeName\\\":\\\"DUCATI\\\"},{\\\"id\\\":\\\"280\\\",\\\"makeName\\\":\\\"EAGLE\\\"},{\\\"id\\\":\\\"297\\\",\\\"makeName\\\":\\\"EFR\\\"},{\\\"id\\\":\\\"21\\\",\\\"makeName\\\":\\\"EICHER\\\"},{\\\"id\\\":\\\"110\\\",\\\"makeName\\\":\\\"ELITE\\\"},{\\\"id\\\":\\\"249\\\",\\\"makeName\\\":\\\"ENGLON\\\"},{\\\"id\\\":\\\"250\\\",\\\"makeName\\\":\\\"ENGLON \\\"},{\\\"id\\\":\\\"240\\\",\\\"makeName\\\":\\\"E-ONE\\\"},{\\\"id\\\":\\\"295\\\",\\\"makeName\\\":\\\"ETEFA\\\"},{\\\"id\\\":\\\"186\\\",\\\"makeName\\\":\\\"EVERLAST\\\"},{\\\"id\\\":\\\"176\\\",\\\"makeName\\\":\\\"FALCON\\\"},{\\\"id\\\":\\\"70\\\",\\\"makeName\\\":\\\"FAW\\\"},{\\\"id\\\":\\\"22\\\",\\\"makeName\\\":\\\"FIAT\\\"},{\\\"id\\\":\\\"256\\\",\\\"makeName\\\":\\\"FIORI\\\"},{\\\"id\\\":\\\"133\\\",\\\"makeName\\\":\\\"FLATBED\\\"},{\\\"id\\\":\\\"23\\\",\\\"makeName\\\":\\\"FORD\\\"},{\\\"id\\\":\\\"222\\\",\\\"makeName\\\":\\\"FORLAND\\\"},{\\\"id\\\":\\\"24\\\",\\\"makeName\\\":\\\"FOTON\\\"},{\\\"id\\\":\\\"148\\\",\\\"makeName\\\":\\\"FRAJEND\\\"},{\\\"id\\\":\\\"170\\\",\\\"makeName\\\":\\\"FREIGHTLINER\\\"},{\\\"id\\\":\\\"151\\\",\\\"makeName\\\":\\\"FUSO\\\"},{\\\"id\\\":\\\"164\\\",\\\"makeName\\\":\\\"GAC\\\"},{\\\"id\\\":\\\"298\\\",\\\"makeName\\\":\\\"Geely\\\"},{\\\"id\\\":\\\"226\\\",\\\"makeName\\\":\\\"GEELY\\\"},{\\\"id\\\":\\\"213\\\",\\\"makeName\\\":\\\"GENIE \\\"},{\\\"id\\\":\\\"277\\\",\\\"makeName\\\":\\\"GENLYON\\\"},{\\\"id\\\":\\\"162\\\",\\\"makeName\\\":\\\"GMC\\\"},{\\\"id\\\":\\\"268\\\",\\\"makeName\\\":\\\"GOLDEN DRAGON\\\"},{\\\"id\\\":\\\"291\\\",\\\"makeName\\\":\\\"GONOW\\\"},{\\\"id\\\":\\\"286\\\",\\\"make,\\\"makeName\\\":\\\"NISSAN\\\"},{\\\"id\\\":\\\"296\\\",\\\"makeName\\\":\\\"OLDSMOBILE\\\"},{\\\"id\\\":\\\"42\\\",\\\"makeName\\\":\\\"OPEL\\\"},{\\\"id\\\":\\\"289\\\",\\\"makeName\\\":\\\"PETERBILT\\\"},{\\\"id\\\":\\\"43\\\",\\\"makeName\\\":\\\"PEUGEOT\\\"},{\\\"id\\\":\\\"105\\\",\\\"makeName\\\":\\\"PIAGGIO\\\"},{\\\"id\\\":\\\"261\\\",\\\"makeName\\\":\\\"POLARSUN\\\"},{\\\"id\\\":\\\"159\\\",\\\"makeName\\\":\\\"PONTIAC\\\"},{\\\"id\\\":\\\"44\\\",\\\"makeName\\\":\\\"PORSCHE\\\"},{\\\"id\\\":\\\"266\\\",\\\"makeName\\\":\\\"PRESIDENT\\\"},{\\\"id\\\":\\\"211\\\",\\\"makeName\\\":\\\"PROTON\\\"},{\\\"id\\\":\\\"253\\\",\\\"makeName\\\":\\\"QINGQI\\\"},{\\\"id\\\":\\\"246\\\",\\\"makeName\\\":\\\"QIPAI\\\"},{\\\"id\\\":\\\"157\\\",\\\"makeName\\\":\\\"QLINK\\\"},{\\\"id\\\":\\\"118\\\",\\\"makeName\\\":\\\"QUON\\\"},{\\\"id\\\":\\\"45\\\",\\\"makeName\\\":\\\"RANDON\\\"},{\\\"id\\\":\\\"47\\\",\\\"makeName\\\":\\\"RENAULT\\\"},{\\\"id\\\":\\\"292\\\",\\\"makeName\\\":\\\"Robinson\\\"},{\\\"id\\\":\\\"197\\\",\\\"makeName\\\":\\\"ROLLS-ROYCE\\\"},{\\\"id\\\":\\\"48\\\",\\\"makeName\\\":\\\"ROVER\\\"},{\\\"id\\\":\\\"207\\\",\\\"makeName\\\":\\\"ROYAL\\\"},{\\\"id\\\":\\\"49\\\",\\\"makeName\\\":\\\"SAAB\\\"},{\\\"id\\\":\\\"130\\\",\\\"makeName\\\":\\\"SACHS\\\"},{\\\"id\\\":\\\"50\\\",\\\"makeName\\\":\\\"SAILORMEIYA\\\"},{\\\"id\\\":\\\"72\\\",\\\"makeName\\\":\\\"SAME\\\"},{\\\"id\\\":\\\"194\\\",\\\"makeName\\\":\\\"SANY\\\"},{\\\"id\\\":\\\"274\\\",\\\"makeName\\\":\\\"SATURN\\\"},{\\\"id\\\":\\\"51\\\",\\\"makeName\\\":\\\"SCANIA\\\"},{\\\"id\\\":\\\"232\\\",\\\"makeName\\\":\\\"SCHWING\\\"},{\\\"id\\\":\\\"172\\\",\\\"makeName\\\":\\\"SCION\\\"},{\\\"id\\\":\\\"221\\\",\\\"makeName\\\":\\\"SEAT\\\"},{\\\"id\\\":\\\"245\\\",\\\"makeName\\\":\\\"SENKE\\\"},{\\\"id\\\":\\\"52\\\",\\\"makeName\\\":\\\"SHACMAN\\\"},{\\\"id\\\":\\\"111\\\",\\\"makeName\\\":\\\"SHANTUI\\\"},{\\\"id\\\":\\\"119\\\",\\\"makeName\\\":\\\"SHENZEN\\\"},{\\\"id\\\":\\\"100\\\",\\\"makeName\\\":\\\"SHINERAY\\\"},{\\\"id\\\":\\\"215\\\",\\\"makeName\\\":\\\"SHIRORO\\\"},{\\\"id\\\":\\\"171\\\",\\\"makeName\\\":\\\"SINO\\\"},{\\\"id\\\":\\\"168\\\",\\\"makeName\\\":\\\"SINOKI SUPRA\\\"},{\\\"id\\\":\\\"53\\\",\\\"makeName\\\":\\\"SINOTRUCK\\\"},{\\\"id\\\":\\\"54\\\",\\\"makeName\\\":\\\"SKODA\\\"},{\\\"id\\\":\\\"108\\\",\\\"makeName\\\":\\\"SKYGO\\\"},{\\\"id\\\":\\\"55\\\",\\\"makeName\\\":\\\"SMART\\\"},{\\\"id\\\":\\\"263\\\",\\\"makeName\\\":\\\"SONLINK\\\"},{\\\"id\\\":\\\"192\\\",\\\"makeName\\\":\\\"SOYAT\\\"},{\\\"id\\\":\\\"56\\\",\\\"makeName\\\":\\\"SSANGYONG\\\"},{\\\"id\\\":\\\"145\\\",\\\"makeName\\\":\\\"STALLION\\\"},{\\\"id\\\":\\\"86\\\",\\\"makeName\\\":\\\"STAR\\\"},{\\\"id\\\":\\\"209\\\",\\\"makeName\\\":\\\"STERLING\\\"},{\\\"id\\\":\\\"281\\\",\\\"makeName\\\":\\\"STEYR\\\"},{\\\"id\\\":\\\"95\\\",\\\"makeName\\\":\\\"STO\\\"},{\\\"id\\\":\\\"57\\\",\\\"makeName\\\":\\\"SUBARU\\\"},{\\\"id\\\":\\\"272\\\",\\\"makeName\\\":\\\"SUPER GALLANT\\\"},{\\\"id\\\":\\\"251\\\",\\\"makeName\\\":\\\"SUPER POWER\\\"},{\\\"id\\\":\\\"153\\\",\\\"makeName\\\":\\\"SUPRA MARS\\\"},{\\\"id\\\":\\\"58\\\",\\\"makeName\\\":\\\"SUZUKI\\\"},{\\\"id\\\":\\\"264\\\",\\\"makeName\\\":\\\"TAFE TRACTOR \\\"},{\\\"id\\\":\\\"193\\\",\\\"makeName\\\":\\\"TANADO\\\"},{\\\"id\\\":\\\"59\\\",\\\"makeName\\\":\\\"TATA\\\"},{\\\"id\\\":\\\"198\\\",\\\"makeName\\\":\\\"TEC\\\"},{\\\"id\\\":\\\"231\\\",\\\"makeName\\\":\\\"TEREX\\\"},{\\\"id\\\":\\\"185\\\",\\\"makeName\\\":\\\"TIANMA\\\"},{\\\"id\\\":\\\"60\\\",\\\"makeName\\\":\\\"TIGO\\\"},{\\\"id\\\":\\\"81\\\",\\\"makeName\\\":\\\"TLD\\\"},{\\\"id\\\":\\\"1\\\",\\\"makeName\\\":\\\"TOYOTA\\\"},{\\\"id\\\":\\\"73\\\",\\\"makeName\\\":\\\"TRACTOR\\\"},{\\\"id\\\":\\\"87\\\",\\\"makeName\\\":\\\"TRAIL KING\\\"},{\\\"id\\\":\\\"77\\\",\\\"makeName\\\":\\\"TRANSTRAILER\\\"},{\\\"id\\\":\\\"134\\\",\\\"makeName\\\":\\\"TRIUMPH\\\"},{\\\"id\\\":\\\"149\\\",\\\"makeName\\\":\\\"TRUMPCHI GAC\\\"},{\\\"id\\\":\\\"202\\\",\\\"makeName\\\":\\\"TUG\\\"},{\\\"id\\\":\\\"78\\\",\\\"makeName\\\":\\\"TVS\\\"},{\\\"id\\\":\\\"165\\\",\\\"makeName\\\":\\\"TWINCO\\\"},{\\\"id\\\":\\\"69\\\",\\\"makeName\\\":\\\"UM\\\"},{\\\"id\\\":\\\"97\\\",\\\"makeName\\\":\\\"VALTRA\\\"},{\\\"id\\\":\\\"61\\\",\\\"makeName\\\":\\\"VAUXHALL\\\"},{\\\"id\\\":\\\"62\\\",\\\"makeName\\\":\\\"VOLKSWAGEN\\\"},{\\\"id\\\":\\\"63\\\",\\\"makeName\\\":\\\"VOLVO\\\"},{\\\"id\\\":\\\"237\\\",\\\"makeName\\\":\\\"VPG\\\"},{\\\"id\\\":\\\"278\\\",\\\"makeName\\\":\\\"Wrangler\\\"},{\\\"id\\\":\\\"64\\\",\\\"makeName\\\":\\\"WUHAN SHENJUN\\\"},{\\\"id\\\":\\\"65\\\",\\\"makeName\\\":\\\"YAMAHA\\\"},{\\\"id\\\":\\\"96\\\",\\\"makeName\\\":\\\"YATIAN\\\"},{\\\"id\\\":\\\"180\\\",\\\"makeName\\\":\\\"YORK\\\"},{\\\"id\\\":\\\"294\\\",\\\"makeName\\\":\\\"YUEJIN\\\"},{\\\"id\\\":\\\"155\\\",\\\"makeName\\\":\\\"YUTONG\\\"},{\\\"id\\\":\\\"173\\\",\\\"makeName\\\":\\\"ZAHAV\\\"},{\\\"id\\\":\\\"260\\\",\\\"makeName\\\":\\\"ZHEJIANG XINCHAI\\\"},{\\\"id\\\":\\\"175\\\",\\\"makeName\\\":\\\"ZHONGTONG\\\"},{\\\"id\\\":\\\"113\\\",\\\"makeName\\\":\\\"ZOOMLION\\\"},{\\\"id\\\":\\\"247\\\",\\\"makeName\\\":\\\"ZOTYE\\\"}]}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-K_HcgpL0Iv"
      },
      "source": [
        "# TEST LEADWAY SUCCESS\n",
        "resultat_leadway = parse_Leadway_Success_Row(leadway_succ)\n",
        "\n",
        "for i in resultat_leadway:\n",
        "  print(resultat_leadway.get(i))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZfl792oBMyw",
        "outputId": "5cfbb85a-4290-490a-ebe4-6a953382305c"
      },
      "source": [
        "2356 in df_raw.index"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho5dPdBwml27"
      },
      "source": [
        "### Function to handle log level \"Error\"\n",
        "NB: faire un docstring (''' ''') pour chaque fonction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLMS5PrDoPIV"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_Error_Row(error_row):\n",
        "  error_row = error_row.replace('\"', \"'\")\n",
        "  pattern = regex.compile(r\"{?[a-z :A-Z 0-9\\\\,=_`']+selfie\")\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  res = res.replace(\"'name'\", \"name\").replace(\"`\", \"\").replace(\"'18'\", \"18\").replace(\"'monthly'\", \"monthly\")\n",
        "  res = res+'\"}'\n",
        "  res = res.replace(\"'\", '\"')\n",
        "  s = json.loads(res)\n",
        "  out_error_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_error_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "  out_error_dump = json.dumps(out_error_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_error_text = json.loads(out_error_dump) # convertir le string json en object json.\n",
        "  return out_error_text\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RZvPvv3FgyK"
      },
      "source": [
        "error_text = parse_Error_Row(df_raw['text'][2355])\n",
        "print(error_text)\n",
        "print(error_text.get('code'))\n",
        "print(error_text.get('errno'))\n",
        "print(error_text.get('sqlMessage'))\n",
        "print(error_text.get('sqlState'))\n",
        "print(error_text.get('index'))\n",
        "print(error_text.get('sql'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9EAlNYIv5x"
      },
      "source": [
        "### Function to convert data to timestamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd-prG9NMlJz"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# function to convert date to Timestamp\n",
        "def convertToTimestamp(str):\n",
        "  element = datetime.datetime.strptime(str,\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "  return datetime.datetime.timestamp(element)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-rZUfpUM3lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45f31a4-5313-449f-8227-788f7f0cd4a1"
      },
      "source": [
        "timestamp = convertToTimestamp('2021-09-05T07:03:55.223Z')\n",
        "timestamp"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1630825435.223"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8TrJS3NHJ6x"
      },
      "source": [
        "## 2 Data model\n",
        "### 2.1 Parse rows of dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "585dRkFQPUbB"
      },
      "source": [
        "### 2.1.1 créer un dictionnary pour les regex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88lZf2qqvQag"
      },
      "source": [
        "type_request_dictionnary = {}\n",
        "regex_list_api_request = []\n",
        "regex_list_api_request.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_api_request.append('/[/a-z 0-9?=&;/_A-Z+]+')\n",
        "regex_list_api_request.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_api_request.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['API REQUEST'] = regex_list_api_request\n",
        "\n",
        "regex_list_client_mobile = []\n",
        "regex_list_client_mobile.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_client_mobile.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_client_mobile.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['CLIENT MOBILE LOGIN'] = regex_list_client_mobile\n",
        "\n",
        "type_request_dictionnary['SMS PAYLOAD'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['SMS SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['WALLET SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['LEADWAY SUCCESS'] = '\\{(?:[^{}]|(?R))*}'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceqzAG_lPsE7"
      },
      "source": [
        "### 2.1.2 Functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AJ6V9HulbOq"
      },
      "source": [
        "### Handle DataFrame Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-IUROmk7Bh"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_error(df_):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  error_code_col = []\n",
        "  error_number_col = []\n",
        "  error_sql_message_col = []\n",
        "  error_sql_state_col = []\n",
        "  error_index_col = []\n",
        "  error_sql_col = []\n",
        "\n",
        "  \n",
        "  list_column_none_level_log_error = []\n",
        "  list_column_none = [message_sms_payload_col, totalsent_col, cost_col, status_col, email_col,\n",
        "                      phone_Col, endpoint_Col, date_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                      responseCode_col, account_name_col, account_number_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    error_code_col, error_number_col, error_sql_message_col, error_sql_state_col, \n",
        "                    error_index_col, error_sql_col]\n",
        "\n",
        "  for index, row in df_.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "    \n",
        "    if re.search('error', str_text):\n",
        "        log_level = re.search('error', str_text)\n",
        "          \n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)\n",
        "\n",
        "        if re.search('LOAN ERROR', str_text):\n",
        "            type_of_request = re.search('LOAN ERROR', str_text)\n",
        "            loan_error = parse_Error_Row(str_text) \n",
        "            try:\n",
        "              error_code_col.append(loan_error.get('code'))\n",
        "              print(error_code_col)\n",
        "            except AttributeError:\n",
        "              error_code_col.append(None)\n",
        "            try:\n",
        "              print(loan_error.get('errno'))\n",
        "              error_number_col.append(loan_error.get('errno'))\n",
        "              print('error number :')\n",
        "              print(error_number_col)\n",
        "            except AttributeError:\n",
        "              error_number_col.append(None)\n",
        "            try:\n",
        "              error_sql_message_col.append(loan_error.get('sqlMessage'))\n",
        "            except AttributeError:\n",
        "              error_sql_message_col.append(None)\n",
        "            try:\n",
        "              error_sql_state_col.append(loan_error.get('sqlState'))\n",
        "            except AttributeError:\n",
        "              error_sql_state_col.append(None)\n",
        "            try:\n",
        "              error_index_col.append(loan_error.get('index'))\n",
        "            except AttributeError:\n",
        "              error_index_col.append(None)\n",
        "            try:\n",
        "              error_sql_col.append(loan_error.get('sql'))\n",
        "            except AttributeError:\n",
        "              error_sql_col.append(None)       \n",
        "\n",
        "            try:\n",
        "                type_request_col.append(type_of_request.group(0))\n",
        "            except AttributeError:\n",
        "                type_request_col.append(None)\n",
        "\n",
        "            for p in range(len(list_column_none)):\n",
        "              list_column_none[p].append(None)\n",
        "  \n",
        "  \n",
        "  #for x in range(len(list_all_colum)):\n",
        "   # print(len(list_all_colum[x]))\n",
        "  \n",
        "  df_['Type_Request'] = type_request_col\n",
        "  df_['Phone_Number'] = phone_Col\n",
        "  df_['Date'] = date_col\n",
        "  df_['EndPoint'] = endpoint_Col\n",
        "  df_['Log_Level'] = log_level_col\n",
        "  df_['Email'] = email_col\n",
        "  df_['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_['Total Sent'] = totalsent_col\n",
        "  df_['Cost'] = cost_col\n",
        "  df_['Status'] = status_col\n",
        "  df_['Account Number'] = account_number_col\n",
        "  df_['Account Name'] = account_name_col\n",
        "  df_['BVN'] = bvn_col\n",
        "  df_['Request Successful'] = requestSuccessful_col\n",
        "  df_['Response Message'] = responseMessage_col\n",
        "  df_['Response Code'] = responseCode_col\n",
        "  df_['Error Code'] = error_code_col\n",
        "  df_['Error Number'] = error_number_col\n",
        "  df_['Error Sql Message'] = error_sql_message_col\n",
        "  df_['Error Sql State'] = error_sql_state_col\n",
        "  df_['Error Index'] = error_index_col\n",
        "  df_['Error Sql'] = error_sql_col\n",
        "\n",
        "\n",
        "  return df_"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-o576_eO32"
      },
      "source": [
        "### Handle DataFrame for error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3poKQQZa6cA0"
      },
      "source": [
        "df_error = df_raw[df_raw['text'].str.contains('LOAN ERROR')]\n",
        "resutat_error = parse_row_error(df_error)\n",
        "resutat_error.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK5QuIgk9xxo"
      },
      "source": [
        "#df_raw = df_raw.drop(2355)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u--eSd8pBL03"
      },
      "source": [
        "df_raw.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B2AIKGMEuuG"
      },
      "source": [
        "### Handle DataFrame for API REQUEST Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0d5QsJ6Db5s"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_api_request(df_api_request):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_api_request = []\n",
        "  list_column_none_api_request = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, account_number_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_api_request.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                \n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][0], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "                               \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)               \n",
        "                try:\n",
        "                  email_col.append(phone_or_email_api_req.group(0)) # add email inside email column\n",
        "                  phone_Col.append(None)  # in this case there is no phone number\n",
        "                except AttributeError:\n",
        "                  email_col.append(None)\n",
        "                try:\n",
        "                  endpoint_Col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_Col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "              \n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                            \n",
        "                # extract a phone number for API REQUEST\n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][3], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_api_req.group(0)) # add phone number inside phone number column\n",
        "                  email_col.append(None) # in this case there is no email address\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  endpoint_Col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_Col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "\n",
        "  df_api_request['Type_Request'] = type_request_col\n",
        "  df_api_request['Phone_Number'] = phone_Col\n",
        "  df_api_request['Date'] = date_col\n",
        "  df_api_request['EndPoint'] = endpoint_Col\n",
        "  df_api_request['Log_Level'] = log_level_col\n",
        "  df_api_request['Email'] = email_col\n",
        "  df_api_request['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_api_request['Total Sent'] = totalsent_col\n",
        "  df_api_request['Cost'] = cost_col\n",
        "  df_api_request['Status'] = status_col\n",
        "  df_api_request['Account Number'] = account_number_col\n",
        "  df_api_request['Account Name'] = account_name_col\n",
        "  df_api_request['BVN'] = bvn_col\n",
        "  df_api_request['Request Successful'] = requestSuccessful_col\n",
        "  df_api_request['Response Message'] = responseMessage_col\n",
        "  df_api_request['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_api_request"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHNYGxLEpl9"
      },
      "source": [
        "df_api_request_ = df_raw[df_raw['text'].str.contains('API REQUEST')]\n",
        "resutat_df_api = parse_row_api_request(df_api_request_)\n",
        "resutat_df_api.head(10)\n",
        "resutat_df_api.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBE4JmynFp2_"
      },
      "source": [
        "### Handle DataFrame for Client Mobile Login Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnVrzUqSFpV1"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_client_mobile_login(df_client_mob):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_client_mobile = []\n",
        "  list_column_none_client_mobile = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, endpoint_Col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_client_mob.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text):   # CLIENT MOBILE LOGIN with email address\n",
        "                  type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                  # extract address email for CLIENT MOBILE LOGIN\n",
        "                  phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][0], str_text)                               \n",
        "                  pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                  datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                  datematcher = datepattern.search(str_text)  # extract date for CLIENT MOBILE LOGIN type request\n",
        "                  \n",
        "                  for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None) \n",
        "                  try:\n",
        "                    email_col.append(phone_or_email_client_mobile.group(0)) # add email inside email column\n",
        "                    phone_Col.append(None)  # in this case there is no phone number\n",
        "                  except AttributeError:\n",
        "                    email_col.append(None)\n",
        "                  try:\n",
        "                    date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                  except AttributeError:\n",
        "                    date_col.append(None)\n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text): # when type request is CLIENT MOBILE LOGIN, there is no EndPoint\n",
        "                type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                # extract a phone number for CLIENT MOBILE LOGIN\n",
        "                phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][2], str_text)                  \n",
        "                pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_client_mobile.group(0))\n",
        "                  email_col.append(None)\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None) \n",
        "\n",
        "  df_client_mob['Type_Request'] = type_request_col\n",
        "  df_client_mob['Phone_Number'] = phone_Col\n",
        "  df_client_mob['Date'] = date_col\n",
        "  df_client_mob['EndPoint'] = endpoint_Col\n",
        "  df_client_mob['Log_Level'] = log_level_col\n",
        "  df_client_mob['Email'] = email_col\n",
        "  df_client_mob['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_client_mob['Total Sent'] = totalsent_col\n",
        "  df_client_mob['Cost'] = cost_col\n",
        "  df_client_mob['Status'] = status_col\n",
        "  df_client_mob['Account Number'] = account_number_col\n",
        "  df_client_mob['Account Name'] = account_name_col\n",
        "  df_client_mob['BVN'] = bvn_col\n",
        "  df_client_mob['Request Successful'] = requestSuccessful_col\n",
        "  df_client_mob['Response Message'] = responseMessage_col\n",
        "  df_client_mob['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_client_mob"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlHywpVGsw4"
      },
      "source": [
        "df_client_mobile_login = df_raw[df_raw['text'].str.contains('CLIENT MOBILE LOGIN')]\n",
        "resutat_df_client_mobile_login = parse_row_client_mobile_login(df_client_mobile_login)\n",
        "resutat_df_client_mobile_login.head()\n",
        "resutat_df_client_mobile_login.info()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5iY2LGHekm"
      },
      "source": [
        "### Handle DataFrame for SMS PAYLOAD Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Iqpe8gHore"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_payload_function(df_sms_payload):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_payload = []\n",
        "  list_column_none_sms_payload = [totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, email_col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_payload.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS PAYLOAD', str_text):\n",
        "                type_of_request = re.search('SMS PAYLOAD', str_text)            \n",
        "                sms_payload = parse_wallet_sms_payload_success(str_text)               \n",
        "                for l in range(len(list_column_none_sms_payload)):\n",
        "                    list_column_none_sms_payload[l].append(None)             \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  phone_Col.append(sms_payload.get('phone'))\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  message_sms_payload_col.append(sms_payload.get('message'))\n",
        "                except AttributeError:\n",
        "                  message_sms_payload_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_sms_payload['Type_Request'] = type_request_col\n",
        "  df_sms_payload['Phone_Number'] = phone_Col\n",
        "  df_sms_payload['Date'] = date_col\n",
        "  df_sms_payload['EndPoint'] = endpoint_Col\n",
        "  df_sms_payload['Log_Level'] = log_level_col\n",
        "  df_sms_payload['Email'] = email_col\n",
        "  df_sms_payload['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_payload['Total Sent'] = totalsent_col\n",
        "  df_sms_payload['Cost'] = cost_col\n",
        "  df_sms_payload['Status'] = status_col\n",
        "  df_sms_payload['Account Number'] = account_number_col\n",
        "  df_sms_payload['Account Name'] = account_name_col\n",
        "  df_sms_payload['BVN'] = bvn_col\n",
        "  df_sms_payload['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_payload['Response Message'] = responseMessage_col\n",
        "  df_sms_payload['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_payload\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etb-rPaJHMZ"
      },
      "source": [
        "df_sms_payload_ = df_raw[df_raw['text'].str.contains('SMS PAYLOAD')]\n",
        "resutat_df_sms_payload = parse_row_sms_payload_function(df_sms_payload_)\n",
        "resutat_df_sms_payload.head()\n",
        "#resutat_df_sms_payload.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz-7pflyJ_Fs"
      },
      "source": [
        "### Handle DataFrame for SMS Success Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJG8_sMYKDKw"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_success_function(df_sms_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_success = []\n",
        "  list_column_none_sms_success = [message_sms_payload_col, account_number_col, bvn_col, requestSuccessful_col, \n",
        "                                  responseMessage_col, responseCode_col, account_name_col, email_col, \n",
        "                                  phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS SUCCESS', str_text): \n",
        "                type_of_request = re.search('SMS SUCCESS', str_text)\n",
        "                sms_success = parse_wallet_sms_payload_success(str_text)                \n",
        "                for m in range(len(list_column_none_sms_success)):\n",
        "                    list_column_none_sms_success[m].append(None) \n",
        "           \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:                 \n",
        "                  totalsent_col.append(sms_success.get('response').get('totalsent '))\n",
        "                except AttributeError:\n",
        "                  totalsent_col.append(None)\n",
        "                try:                 \n",
        "                  cost_col.append(sms_success.get('response').get('cost '))\n",
        "                except AttributeError:\n",
        "                  cost_col.append(None)\n",
        "                try:                 \n",
        "                  status_col.append(sms_success.get('response').get('status '))\n",
        "                except AttributeError:\n",
        "                  status_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)    \n",
        "\n",
        "  df_sms_success['Type_Request'] = type_request_col\n",
        "  df_sms_success['Phone_Number'] = phone_Col\n",
        "  df_sms_success['Date'] = date_col\n",
        "  df_sms_success['EndPoint'] = endpoint_Col\n",
        "  df_sms_success['Log_Level'] = log_level_col\n",
        "  df_sms_success['Email'] = email_col\n",
        "  df_sms_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_success['Total Sent'] = totalsent_col\n",
        "  df_sms_success['Cost'] = cost_col\n",
        "  df_sms_success['Status'] = status_col\n",
        "  df_sms_success['Account Number'] = account_number_col\n",
        "  df_sms_success['Account Name'] = account_name_col\n",
        "  df_sms_success['BVN'] = bvn_col\n",
        "  df_sms_success['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_success['Response Message'] = responseMessage_col\n",
        "  df_sms_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_success\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWOAd_5KmGM"
      },
      "source": [
        "df_sms_success_ = df_raw[df_raw['text'].str.contains('SMS SUCCESS')]\n",
        "resutat_df_sms_success = parse_row_sms_success_function(df_sms_success_)\n",
        "resutat_df_sms_success.head()\n",
        "#resutat_df_sms_success.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMxkpxxcK72K"
      },
      "source": [
        "### Handle DataFrame for WALLET SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-XB7evJLGvD"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_wallet_success_function(df_wallet_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_wallet_success = []\n",
        "  list_column_none_wallet_success = [totalsent_col, message_sms_payload_col, cost_col, status_col, \n",
        "                                     email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "  \n",
        "  for index, row in df_wallet_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('WALLET SUCCESS', str_text):\n",
        "                  wallet_success = parse_wallet_sms_payload_success(str_text)\n",
        "                  type_of_request = re.search('WALLET SUCCESS', str_text)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                  try:\n",
        "                    account_number_col.append(wallet_success.get('account_number'))\n",
        "                  except AttributeError:\n",
        "                    account_number_col.append(None)\n",
        "                  try:\n",
        "                    account_name_col.append(wallet_success.get('account_name'))\n",
        "                  except AttributeError:\n",
        "                    account_name_col.append(None)\n",
        "                  try:\n",
        "                    bvn_col.append(wallet_success.get('bvn'))\n",
        "                  except AttributeError:\n",
        "                    bvn_col.append(None)\n",
        "                  try:\n",
        "                    requestSuccessful_col.append(wallet_success.get('requestSuccessful'))\n",
        "                  except AttributeError:\n",
        "                    requestSuccessful_col.append(None)\n",
        "                  try:\n",
        "                    responseMessage_col.append((wallet_success.get('responseMessage')))\n",
        "                  except AttributeError:\n",
        "                    responseMessage_col.append(None)\n",
        "                  try:\n",
        "                    responseCode_col.append((wallet_success.get('responseCode')))\n",
        "                  except AttributeError:\n",
        "                    responseCode_col.append(None)\n",
        "                  for n in range(len(list_column_none_wallet_success)):\n",
        "                    list_column_none_wallet_success[n].append(None) \n",
        "\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)    \n",
        "\n",
        "  df_wallet_success['Type_Request'] = type_request_col\n",
        "  df_wallet_success['Phone_Number'] = phone_Col\n",
        "  df_wallet_success['Date'] = date_col\n",
        "  df_wallet_success['EndPoint'] = endpoint_Col\n",
        "  df_wallet_success['Log_Level'] = log_level_col\n",
        "  df_wallet_success['Email'] = email_col\n",
        "  df_wallet_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_wallet_success['Total Sent'] = totalsent_col\n",
        "  df_wallet_success['Cost'] = cost_col\n",
        "  df_wallet_success['Status'] = status_col\n",
        "  df_wallet_success['Account Number'] = account_number_col\n",
        "  df_wallet_success['Account Name'] = account_name_col\n",
        "  df_wallet_success['BVN'] = bvn_col\n",
        "  df_wallet_success['Request Successful'] = requestSuccessful_col\n",
        "  df_wallet_success['Response Message'] = responseMessage_col\n",
        "  df_wallet_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_wallet_success\n",
        "             "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVPZi-uGMbDU"
      },
      "source": [
        "df_wallet_success_ = df_raw[df_raw['text'].str.contains('WALLET SUCCESS')]\n",
        "resutat_df_wallet_success = parse_row_wallet_success_function(df_wallet_success_)\n",
        "resutat_df_wallet_success.head()\n",
        "#resutat_df_wallet_success.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4IzATOC-s2M"
      },
      "source": [
        "okra = parse_wallet_sms_payload_success(df_raw['text'][0])\n",
        "print(okra.get('authorization').get('customer '))\n",
        "print(okra.get('authorization').get('env '))\n",
        "print(okra.get('authorization').get('owner '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mps5LhixM8Zo"
      },
      "source": [
        "### Handle DataFrame for OKRA WEBHOOK Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUDyIGEM8yc"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_okra_webhook_function(df_okra):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  accountId_col = []\n",
        "  authorization_v_col = []\n",
        "  authorization_id_col = []\n",
        "  authorization_customer_col = []\n",
        "  authorization_account_col = []\n",
        "  authorization_account_id_col = []\n",
        "  authorization_account_manual_col = []\n",
        "  authorization_account_name_col = []\n",
        "  authorization_account_nuban_col = []\n",
        "  authorization_account_bank_col = []\n",
        "  authorization_account_created_at_col = []\n",
        "  authorization_account_last_updated_col = []\n",
        "  authorization_account_balance_col = []\n",
        "  authorization_account_customer_col = []\n",
        "  authorization_account_type_col = []\n",
        "  authorization_account_currency_col = []\n",
        "  authorization_accounts_col = []\n",
        "  authorization_amount_col = []\n",
        "  authorization_bank_col = []\n",
        "  authorization_created_at_col = []\n",
        "  authorization_currency_col = []\n",
        "  authorization_customerDetails_col = []\n",
        "  authorization_disconnect_col = []\n",
        "  authorization_disconnected_at_col = []\n",
        "  authorization_duration_col = []\n",
        "  authorization_env_col = []\n",
        "  authorization_garnish_col = []\n",
        "  authorization_initialAmount_col = []\n",
        "  authorization_initiated_col = []\n",
        "  authorization_last_updated_col = []\n",
        "  authorization_link_col = []\n",
        "  authorization_next_payment_col = []\n",
        "  authorization_owner_col = []\n",
        "  authorization_payLink_col = []\n",
        "  authorization_type_col = []\n",
        "  authorization_used_col = []\n",
        "  authorizationId_col = []\n",
        "  bankId_col = []\n",
        "  bankName_col = []\n",
        "  bankSlug_col = []\n",
        "  bankType_col = []\n",
        "  callbackURL_col = []\n",
        "  callback_code_col = []\n",
        "  callback_type_col = []\n",
        "  callback_url_col = []\n",
        "  code_col = []\n",
        "  country_col = []\n",
        "  current_project_col = []\n",
        "  customerEmail_col = []\n",
        "  customerId_col = []\n",
        "  ended_at_col = []\n",
        "  env_col = []\n",
        "  extras_col = []\n",
        "  identityType_col = []\n",
        "  login_type_col = []\n",
        "  message_col = []\n",
        "  meta_col = []\n",
        "  method_col = []\n",
        "  options_col = []\n",
        "  owner_col = []\n",
        "  record_col = []\n",
        "  recordId_col = []\n",
        "  started_at_col = []\n",
        "  status_webhook_col = []\n",
        "  token_col = []\n",
        "  type_col = []\n",
        "\n",
        "  list_column_none_okra_webhook = []\n",
        "  list_column_none_okra_webhook = [api_request_col, account_number_col, account_name_col, totalsent_col, \n",
        "                                   message_sms_payload_col, cost_col, status_col, responseCode_col,\n",
        "                                   bvn_col, requestSuccessful_col, responseMessage_col, email_col, phone_Col, \n",
        "                                   endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_okra.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('OKRA WEBHOOK', str_text):\n",
        "                  type_of_request = re.search('OKRA WEBHOOK', str_text)\n",
        "                  okra_webhook = parse_wallet_sms_payload_success(str_text)                  \n",
        "                  accountId_col.append(okra_webhook.get('accountId'))\n",
        "                  authorization_v_col.append(okra_webhook.get('authorization').get('__v '))\n",
        "                  authorization_id_col.append(okra_webhook.get('authorization').get('_id '))\n",
        "                  authorization_customer_col.append(okra_webhook.get('authorization').get('customer '))\n",
        "                  authorization_account_col.append(okra_webhook.get('authorization').get('account '))\n",
        "                  authorization_account_id_col.append(okra_webhook.get('authorization').get('account ')[0].get('_id '))\n",
        "                  authorization_account_manual_col.append(okra_webhook.get('authorization').get('account ')[0].get('manual '))\n",
        "                  authorization_account_name_col.append(okra_webhook.get('authorization').get('account ')[0].get('name '))\n",
        "                  authorization_account_nuban_col.append(okra_webhook.get('authorization').get('account ')[0].get('nuban '))\n",
        "                  authorization_account_bank_col.append(okra_webhook.get('authorization').get('account ')[0].get('bank '))\n",
        "                  authorization_account_created_at_col.append(okra_webhook.get('authorization').get('account ')[0].get('created_at '))\n",
        "                  authorization_account_last_updated_col.append(okra_webhook.get('authorization').get('account ')[0].get('last_updated '))\n",
        "                  authorization_account_balance_col.append(okra_webhook.get('authorization').get('account ')[0].get('balance '))\n",
        "                  authorization_account_customer_col.append(okra_webhook.get('authorization').get('account ')[0].get('customer '))\n",
        "                  authorization_account_type_col.append(okra_webhook.get('authorization').get('account ')[0].get('type '))\n",
        "                  authorization_account_currency_col.append(okra_webhook.get('authorization').get('account ')[0].get('currency '))\n",
        "                  authorization_accounts_col.append(okra_webhook.get('authorization').get('accounts '))\n",
        "                  authorization_amount_col.append(okra_webhook.get('authorization').get('amount '))\n",
        "                  authorization_bank_col.append(okra_webhook.get('authorization').get('bank '))\n",
        "                  authorization_created_at_col.append(okra_webhook.get('authorization').get('created_at '))\n",
        "                  authorization_currency_col.append(okra_webhook.get('authorization').get('currency '))\n",
        "                  authorization_customerDetails_col.append(okra_webhook.get('authorization').get('customerDetails '))\n",
        "                  authorization_disconnect_col.append(okra_webhook.get('authorization').get('disconnect '))\n",
        "                  authorization_disconnected_at_col.append(okra_webhook.get('authorization').get('disconnected_at '))\n",
        "                  authorization_duration_col.append(okra_webhook.get('authorization').get('duration '))\n",
        "                  authorization_env_col.append(okra_webhook.get('authorization').get('env '))\n",
        "                  authorization_garnish_col.append(okra_webhook.get('authorization').get('garnish '))\n",
        "                  authorization_initialAmount_col.append(okra_webhook.get('authorization').get('initialAmount '))\n",
        "                  authorization_initiated_col.append(okra_webhook.get('authorization').get('initiated '))\n",
        "                  authorization_last_updated_col.append(okra_webhook.get('authorization').get('last_updated '))\n",
        "                  authorization_link_col.append(okra_webhook.get('authorization').get('link '))\n",
        "                  authorization_next_payment_col.append(okra_webhook.get('authorization').get('next_payment '))\n",
        "                  authorization_owner_col.append(okra_webhook.get('authorization').get('owner '))\n",
        "                  authorization_payLink_col.append(okra_webhook.get('authorization').get('payLink '))\n",
        "                  authorization_type_col.append(okra_webhook.get('authorization').get('type '))\n",
        "                  authorization_used_col.append(okra_webhook.get('authorization').get('used '))\n",
        "                  authorizationId_col.append(okra_webhook.get('authorizationId'))\n",
        "                  bankId_col.append(okra_webhook.get('bankId'))\n",
        "                  bankName_col.append(okra_webhook.get('bankName'))\n",
        "                  bankSlug_col.append(okra_webhook.get('bankSlug'))\n",
        "                  bankType_col.append(okra_webhook.get('bankType'))\n",
        "                  callbackURL_col.append(okra_webhook.get('callbackURL'))\n",
        "                  callback_code_col.append(okra_webhook.get('callback_code'))\n",
        "                  callback_type_col.append(okra_webhook.get('callback_type'))\n",
        "                  callback_url_col.append(okra_webhook.get('callback_url'))\n",
        "                  code_col.append(okra_webhook.get('code'))\n",
        "                  country_col.append(okra_webhook.get('country'))\n",
        "                  current_project_col.append(okra_webhook.get('current_project'))\n",
        "                  customerEmail_col.append(okra_webhook.get('customerEmail'))\n",
        "                  customerId_col.append(okra_webhook.get('customerId'))\n",
        "                  ended_at_col.append(okra_webhook.get('ended_at'))\n",
        "                  env_col.append(okra_webhook.get('env'))\n",
        "                  extras_col.append(okra_webhook.get('extras'))\n",
        "                  identityType_col.append(okra_webhook.get('identityType'))\n",
        "                  login_type_col.append(okra_webhook.get('login_type'))\n",
        "                  message_col.append(okra_webhook.get('message'))\n",
        "                  meta_col.append(okra_webhook.get('meta'))\n",
        "                  method_col.append(okra_webhook.get('method'))\n",
        "                  options_col.append(okra_webhook.get('options'))\n",
        "                  owner_col.append(okra_webhook.get('owner'))\n",
        "                  record_col.append(okra_webhook.get('record'))\n",
        "                  recordId_col.append(okra_webhook.get('recordId'))\n",
        "                  started_at_col.append(okra_webhook.get('started_at'))\n",
        "                  status_webhook_col.append(okra_webhook.get('status'))\n",
        "                  token_col.append(okra_webhook.get('token'))\n",
        "                  type_col.append(okra_webhook.get('type'))\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                  \n",
        "                  for n in range(len(list_column_none_okra_webhook)):\n",
        "                    list_column_none_okra_webhook[n].append(None)\n",
        "\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "       \n",
        "  df_okra['Type_Request'] = type_request_col\n",
        "  df_okra['Phone_Number'] = phone_Col\n",
        "  df_okra['Date'] = date_col\n",
        "  df_okra['EndPoint'] = endpoint_Col\n",
        "  df_okra['Log_Level'] = log_level_col\n",
        "  df_okra['Email'] = email_col\n",
        "  df_okra['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_okra['Total Sent'] = totalsent_col\n",
        "  df_okra['Cost'] = cost_col\n",
        "  df_okra['Status'] = status_col\n",
        "  df_okra['Account Number'] = account_number_col\n",
        "  df_okra['Account Name'] = account_name_col\n",
        "  df_okra['BVN'] = bvn_col\n",
        "  df_okra['Request Successful'] = requestSuccessful_col\n",
        "  df_okra['Response Message'] = responseMessage_col\n",
        "  df_okra['Response Code'] = responseCode_col\n",
        "  df_okra['Account Id'] = accountId_col\n",
        "  df_okra['Authorization_V'] = authorization_v_col\n",
        "  df_okra['Authorization_Id'] = authorization_id_col\n",
        "  df_okra['Authorization_Customer'] = authorization_customer_col\n",
        "  df_okra['Authorization_Owner'] = authorization_owner_col\n",
        "  df_okra['Authorization_Account'] = authorization_account_col\n",
        "  df_okra['Authorization_account_Id'] = authorization_account_id_col\n",
        "  df_okra['Authorization_account_manual'] = authorization_account_manual_col\n",
        "  df_okra['Authorization_account_name'] = authorization_account_name_col\n",
        "  df_okra['Authorization_account_nuban'] = authorization_account_nuban_col\n",
        "  df_okra['Authorization_account_bank'] = authorization_account_bank_col\n",
        "  df_okra['Authorization_account_created_at'] = authorization_account_created_at_col\n",
        "  df_okra['Authorization_account_last_updated'] = authorization_account_last_updated_col\n",
        "  df_okra['Authorization_account_balance'] = authorization_account_balance_col\n",
        "  df_okra['Authorization_account_customer'] = authorization_account_customer_col\n",
        "  df_okra['Authorization_account_type'] = authorization_account_type_col\n",
        "  df_okra['Authorization_account_currency'] = authorization_account_currency_col\n",
        "  df_okra['Authorization_accounts'] = authorization_accounts_col\n",
        "  df_okra['Authorization_amount'] = authorization_amount_col\n",
        "  df_okra['Authorization_bank'] = authorization_bank_col\n",
        "  df_okra['Authorization_created_at'] = authorization_created_at_col\n",
        "  df_okra['Authorization_currency'] = authorization_currency_col \n",
        "  df_okra['Authorization_customerDetails'] = authorization_customerDetails_col\n",
        "  df_okra['Authorization_disconnect'] = authorization_disconnect_col\n",
        "  df_okra['Authorization_disconnected_at'] = authorization_disconnected_at_col\n",
        "  df_okra['Authorization_duration'] = authorization_duration_col\n",
        "  df_okra['Authorization_env'] = authorization_env_col\n",
        "  df_okra['Authorization_garnish'] = authorization_garnish_col\n",
        "  df_okra['Authorization_initialAmount'] = authorization_initialAmount_col\n",
        "  df_okra['Authorization_initiated'] = authorization_initiated_col\n",
        "  df_okra['Authorization_last_updated'] = authorization_last_updated_col\n",
        "  df_okra['Authorization_link'] = authorization_link_col\n",
        "  df_okra['Authorization_next_payment'] = authorization_next_payment_col\n",
        "  df_okra['Authorization_payLink'] = authorization_payLink_col\n",
        "  df_okra['Authorization_type'] = authorization_type_col\n",
        "  df_okra['Authorization_used'] = authorization_used_col\n",
        "  df_okra['AuthorizationId'] = authorizationId_col\n",
        "  df_okra['BankId'] = bankId_col\n",
        "  df_okra['BankName'] = bankName_col\n",
        "  df_okra['bankSlug'] = bankSlug_col\n",
        "  df_okra['bankType'] = bankType_col\n",
        "  df_okra['callbackURL'] = callbackURL_col\n",
        "  df_okra['callback_code'] = callback_code_col\n",
        "  df_okra['callback_type'] = callback_type_col \n",
        "  df_okra['callback_url'] = callback_url_col\n",
        "  df_okra['code'] = code_col\n",
        "  df_okra['country'] = country_col\n",
        "  df_okra['current_project'] = current_project_col\n",
        "  df_okra['customerEmail'] = customerEmail_col\n",
        "  df_okra['customerId'] = customerId_col\n",
        "  df_okra['ended_at'] = ended_at_col\n",
        "  df_okra['env'] = env_col\n",
        "  df_okra['extras'] = extras_col\n",
        "  df_okra['identityType'] = identityType_col\n",
        "  df_okra['login_type'] = login_type_col\n",
        "  df_okra['message'] = message_col\n",
        "  df_okra['meta'] = meta_col\n",
        "  df_okra['method'] = method_col\n",
        "  df_okra['options'] = options_col\n",
        "  df_okra['owner'] = owner_col\n",
        "  df_okra['record'] = record_col \n",
        "  df_okra['recordId'] = recordId_col\n",
        "  df_okra['started_at'] = started_at_col\n",
        "  df_okra['status_webhook'] = status_webhook_col\n",
        "  df_okra['token'] = token_col\n",
        "  df_okra['type'] = type_col\n",
        " \n",
        "  return df_okra\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4ZjQeK3Z10"
      },
      "source": [
        "df_okra_webhook = df_raw[df_raw['text'].str.contains('OKRA WEBHOOK')]\n",
        "parse_row_okra_webhook_function(df_okra_webhook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWmCvYp3SXf"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPh9NrF2OND7"
      },
      "source": [
        "### Handle DataFrame for LEADWAY SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWOCepv9ONYw"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_leadway_function(df_leadway_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_leadway_success = []\n",
        "  list_column_none_leadway_success = [message_sms_payload_col, totalsent_col, cost_col, status_col, \n",
        "                                     account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                     responseCode_col, account_name_col, email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_leadway_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('LEADWAY SUCCESS', str_text):\n",
        "                  type_of_request = re.search('LEADWAY SUCCESS', str_text)\n",
        "                  leadway_success_concat_text, index_first_succ, index_last_succ = parse_and_concatenate_Leadway_Success_Rows(df_)\n",
        "                  res_text_leadway = parse_Leadway_Success_Row(leadway_success_concat_text)\n",
        "                  for o in range(len(list_column_none_leadway_success)):\n",
        "                    list_column_none_leadway_success[o].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                   \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_leadway_success['Type_Request'] = type_request_col\n",
        "  df_leadway_success['Phone_Number'] = phone_Col\n",
        "  df_leadway_success['Date'] = date_col\n",
        "  df_leadway_success['EndPoint'] = endpoint_Col\n",
        "  df_leadway_success['Log_Level'] = log_level_col\n",
        "  df_leadway_success['Email'] = email_col\n",
        "  df_leadway_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_leadway_success['Total Sent'] = totalsent_col\n",
        "  df_leadway_success['Cost'] = cost_col\n",
        "  df_leadway_success['Status'] = status_col\n",
        "  df_leadway_success['Account Number'] = account_number_col\n",
        "  df_leadway_success['Account Name'] = account_name_col\n",
        "  df_leadway_success['BVN'] = bvn_col\n",
        "  df_leadway_success['Request Successful'] = requestSuccessful_col\n",
        "  df_leadway_success['Response Message'] = responseMessage_col\n",
        "  df_leadway_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_leadway_success\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFTSv_Y0mcjO"
      },
      "source": [
        "### Concatenate DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-VL2Igymfck"
      },
      "source": [
        "pdList = [df_error, resutat_df_api, resutat_df_client_mobile_login, resutat_df_sms_payload, \n",
        "          resutat_df_sms_success, resutat_df_wallet_success, df_okra_webhook]  # List of our dataframes\n",
        "df_final = pd.concat(pdList)\n",
        "df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qsXB16xUGyd"
      },
      "source": [
        "### Export final Dataframe to a file csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyP128bIS8o1"
      },
      "source": [
        "df_final.to_csv('/content/drive/MyDrive/datasets/nirra_log_bot.csv', index=None)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwMHt6A2r8fL",
        "outputId": "6d5072d1-b37a-4166-988a-ae75fc33b921"
      },
      "source": [
        "len(df_final['Phone_Number'].unique())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tAOylN7OU99"
      },
      "source": [
        "### Récupérer les numéros de téléphone différents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z47mOjmAOkCM"
      },
      "source": [
        "df_final['Phone_Number'].unique() # récupérer la liste des différents numéros de téléphone\n",
        "all_users_phone_number = [element for element in df_final['Phone_Number'].unique() if element != None] # all userId\n",
        "all_users_phone_number # liste de tous les différents numéros de téléphone.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOulnkEKP-Wr"
      },
      "source": [
        "all_df_phone_number = [] # to get list of dataframes\n",
        "for phoneNumber in all_users_phone_number:\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber] # récupérer les dataframes avec seulement les numéros de téléphone\n",
        "  all_df_phone_number.append(df_phone_number)  # mettre chaque dataframe dans la\n",
        "\n",
        "all_df_phone_number[0] # print the first dataframe inside the list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_tvM7PdRSE0"
      },
      "source": [
        "### sauvegarder les dataframes sur disque "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq3drem3RRm2",
        "outputId": "526792c3-648c-446b-f0b5-86e089cc1096"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# tqdm permet\n",
        "for phoneNumber in tqdm(all_users_phone_number):\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber]\n",
        "  df_phone_number.to_csv(f'/content/drive/MyDrive/datasets/files/{phoneNumber}.csv', index=None)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:01<00:00, 88.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNwcH2kFnpiP",
        "outputId": "c8f4534f-f8f4-4fd7-9faf-6e23e4ab81c1"
      },
      "source": [
        "print(len(all_users_phone_number))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cct87UPHuM_7",
        "outputId": "971856bf-dc28-4c21-832f-83a7a1464731"
      },
      "source": [
        "cd /content/drive/MyDrive/datasets/files/"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGN3PMQmuSot"
      },
      "source": [
        "def isNaN(string):\n",
        "    return string != string"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YixcW0AMuTYZ",
        "outputId": "41a9c55c-aa12-4a3b-dfd1-7a72bfe587a4"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# use glob to get all the csv files \n",
        "# in the folder\n",
        "path = os.getcwd()\n",
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "all_df_list = [] # list of all dataframe\n",
        "# loop over the list of csv files\n",
        "number_transactions = []\n",
        "all_df_list_with_number_transaction = []\n",
        "all_df_with_diff_ts = []\n",
        "\n",
        "for f in tqdm(csv_files):    \n",
        "    # read the csv file\n",
        "    df = pd.read_csv(f)  \n",
        "    all_df_list.append(df)   \n",
        "\n",
        "for element in all_df_list:\n",
        "  element['Number_Transactions'] = element.shape[0] # faire la somme des lignes et mettre dans la colonne Number_Transactions\n",
        "  all_df_list_with_number_transaction.append(element)# mettre tous les éléments dans une nouvelle liste\n",
        "\n",
        "#Faire la différence entre les timestamp\n",
        "for ele_with_num_trans in all_df_list_with_number_transaction:\n",
        "  df_ts = pd.DataFrame(ele_with_num_trans['ts'])\n",
        "  ele_with_num_trans['ts_diff'] = df_ts.diff(axis=0)\n",
        "  all_df_with_diff_ts.append(ele_with_num_trans)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:00<00:00, 123.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eiTbqq3uQjd",
        "outputId": "70cbfe95-43cb-43b5-cbcf-f5be95906ece"
      },
      "source": [
        "print(len(all_df_list_with_number_transaction))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HqVdxVugXu",
        "outputId": "0d04164a-3037-40fd-9409-b56d916e4fc2"
      },
      "source": [
        "print(len(all_df_with_diff_ts))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pqKluVvIo4"
      },
      "source": [
        "all_df_with_diff[50].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtRP6naGtge1"
      },
      "source": [
        "### Faire le plot en fonction du nombre des transactions et de la différence entre timestamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MghFTVudtc6O"
      },
      "source": [
        "# Faire des plots pour chaque utilisateur\n",
        "for ele_plot in all_df_with_diff_ts:\n",
        "  attributes = [\"Number_Transactions\", \"ts_diff\"]\n",
        "  #scatter_matrix(ele_plot[attributes], figsize=(10, 5))\n",
        "  #plt.show()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnGwIcUmR9yO"
      },
      "source": [
        "### Création des times series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGmlFq2QtTa1",
        "outputId": "8c97cf13-8226-4299-c401-1cc280d3587a"
      },
      "source": [
        "all_df_res = []\n",
        "new_endpoint_col = []\n",
        "for new_data_frame in tqdm(all_df_with_diff_ts):\n",
        "  new_data_frame['EndPoint'].fillna('', inplace=True) # modifie la colonne\n",
        "\n",
        "  new_data_frame['Appplication_get'] = new_data_frame['EndPoint'].str.contains('applications/get').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Payment'] = new_data_frame['EndPoint'].str.contains('payment').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Declined'] = new_data_frame['EndPoint'].str.contains('decline').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Preapprouved'] = new_data_frame['EndPoint'].str.contains('preapproved').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Accepted'] = new_data_frame['EndPoint'].str.contains('accept').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Lifestyle'] = new_data_frame['EndPoint'].str.contains('lifestyle').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Wallet_balance'] = new_data_frame['EndPoint'].str.contains('wallet/balance').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Adverts'] = new_data_frame['EndPoint'].str.contains('adverts').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Bank'] = new_data_frame['EndPoint'].str.contains('bank').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Updated'] = new_data_frame['EndPoint'].str.contains('update').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Products'] = new_data_frame['EndPoint'].str.contains('products').astype(np.float).astype('Int32')\n",
        "  new_data_frame['Locations'] = new_data_frame['EndPoint'].str.contains('locations').astype(np.float).astype('Int32')\n",
        "    \n",
        "  new_data_frame['Dummy'] = 0\n",
        "  new_data_frame['Payment_cumulative'] = new_data_frame.groupby(['Dummy'])['Payment'].cumsum()\n",
        "  new_data_frame['Decline_cumulative'] = new_data_frame.groupby(['Dummy'])['Declined'].cumsum()\n",
        "  new_data_frame['Application_get_cumulative'] = new_data_frame.groupby(['Dummy'])['Appplication_get'].cumsum()\n",
        "  new_data_frame['Preapprouved_cumulative'] = new_data_frame.groupby(['Dummy'])['Preapprouved'].cumsum()\n",
        "  new_data_frame['Accepted_cumulative'] = new_data_frame.groupby(['Dummy'])['Accepted'].cumsum()\n",
        "  new_data_frame['Lifestyle_cumulative'] = new_data_frame.groupby(['Dummy'])['Lifestyle'].cumsum()\n",
        "  new_data_frame['Wallet_balance_cumulative'] = new_data_frame.groupby(['Dummy'])['Wallet_balance'].cumsum()\n",
        "  new_data_frame['Adverts_cumulative'] = new_data_frame.groupby(['Dummy'])['Adverts'].cumsum()\n",
        "  new_data_frame['Bank_cumulative'] = new_data_frame.groupby(['Dummy'])['Bank'].cumsum()\n",
        "  new_data_frame['Update_cumulative'] = new_data_frame.groupby(['Dummy'])['Updated'].cumsum()\n",
        "  new_data_frame['Products_cumulative'] = new_data_frame.groupby(['Dummy'])['Products'].cumsum()\n",
        "  new_data_frame['Locations_cumulative'] = new_data_frame.groupby(['Dummy'])['Locations'].cumsum()\n",
        "  all_df_res.append(new_data_frame)\n",
        "        "
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:03<00:00, 29.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nJNZz1DrQT1",
        "outputId": "c6405562-e150-4e0b-de3e-96ba14bf1be6"
      },
      "source": [
        "print(len(all_df_list))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr4jNrsyPMQB",
        "outputId": "3261e9a6-b27a-43a1-eacc-5e2c422bf709"
      },
      "source": [
        "print(len(all_df_res))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsiqfAlHQzuz"
      },
      "source": [
        "df_de_test = all_df_res[0]\n",
        "df_de_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81PMY2XhQ85K",
        "outputId": "e6e0f382-b129-422e-c085-cb91a32f337f"
      },
      "source": [
        "df_de_test['EndPoint'].str.contains('/client/').sum()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxF2xJfhUeo",
        "outputId": "19e28430-1e76-45bd-9881-f0fb23737150"
      },
      "source": [
        "cd /content/drive/My Drive/datasets/new_files"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/datasets/new_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qebtQVU8k2hr"
      },
      "source": [
        "### Sauvegarder les nouveaux datasets dans un nouveau dossier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXcimjuqS7ya",
        "outputId": "18082b14-72fb-4e0c-bf10-5bb39f691f78"
      },
      "source": [
        "from tqdm import tqdm\n",
        " #tqdm permet\n",
        "for elem in tqdm(all_df_res):\n",
        "  phone = elem['Phone_Number'][0]\n",
        "  elem.to_csv(f'/content/drive/MyDrive/datasets/new_files/{phone}.csv', index=None)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:01<00:00, 69.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ehcDoaPUFR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZNt34l9ykd-",
        "outputId": "76480ef9-adf1-4d56-90af-e7a08f4df95e"
      },
      "source": [
        "path = os.getcwd()\n",
        "csv_files_new = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "all_df_list_new = []\n",
        "# loop over the list of csv files\n",
        "for f in tqdm(csv_files_new):    \n",
        "    # read the csv file\n",
        "    df_new = pd.read_csv(f)  \n",
        "    all_df_list_new.append(df_new)\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:01<00:00, 101.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fzLc7xU0wm"
      },
      "source": [
        "### liste des opérations par utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuTubWpVbVfE"
      },
      "source": [
        "test_list.sort()\n",
        "mid = len(test_list) // 2\n",
        "res = (test_list[mid] + test_list[~mid]) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nVEiYCjdice"
      },
      "source": [
        "### extraction d'une  métrique pour le nombre d'opérations effectuées par un utilisateur sur la base de l'endpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHzbosvqfDl9"
      },
      "source": [
        "# liste des personnes à risque\n",
        "list_personnes_risque = []"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBoPMdfkY0C-",
        "outputId": "a82cb176-6c60-4933-b9af-f193af53bca3"
      },
      "source": [
        "import statistics\n",
        "new_data_frame['EndPoint'].fillna('', inplace=True)\n",
        "sum_operation = []\n",
        "numero_tel = []\n",
        "for eleme in all_df_list_new:\n",
        "  eleme['EndPoint'].fillna('', inplace=True)\n",
        "  sum_operation.append(eleme['EndPoint'].str.contains('/client/').sum())\n",
        "\n",
        "print(sum_operation)  \n",
        "minimum = min(sum_operation)\n",
        "maximum = max(sum_operation)\n",
        "mediane = statistics.median(sum_operation)\n",
        "moyenne = statistics.mean(sum_operation)\n",
        "ecart_type = statistics.pstdev(sum_operation)\n",
        "print(ecart_type)\n",
        "thresold = 3*ecart_type # les valeurs au délà de 3* écart type sont considérés comme outliers, on considère cette valeur comme notre seuil\n",
        "print(thresold)\n",
        "  "
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19, 80, 15, 2, 47, 13, 41, 290, 143, 43, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 3, 98, 58, 48, 10, 54, 154, 194, 3, 25, 51, 139, 69, 120, 35, 38, 14, 12, 90, 83, 134, 10, 26, 84, 4, 188, 35, 24, 28, 34, 21, 192, 9, 75, 31, 110, 384, 225, 1, 49, 27, 19, 89, 126, 44, 17, 16, 49, 244, 181, 13, 50, 5, 77, 26, 57]\n",
            "67.26812023536856\n",
            "201.80436070610568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1f_J2ugelNj",
        "outputId": "31d3589e-221b-4df4-b47d-0cd5a1fbfd5c"
      },
      "source": [
        "new_data_frame['EndPoint'].fillna('', inplace=True)\n",
        "list_operateurs = []\n",
        "numero_tel = []\n",
        "for eleme in all_df_list_new:\n",
        "  eleme['EndPoint'].fillna('', inplace=True)\n",
        "  if eleme['EndPoint'].str.contains('/client/').sum() > 200 :\n",
        "    list_operateurs.append(eleme)\n",
        "    list_personnes_risque.append(eleme)\n",
        "print(len(list_operateurs))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIX39hu4d3aA"
      },
      "source": [
        "### rechercher le nombre d'utilisateurs qui ont le payement \"declined\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kezT3M2qbwrX"
      },
      "source": [
        "import statistics\n",
        "new_data_frame['EndPoint'].fillna('', inplace=True)\n",
        "declined_operation = []\n",
        "numero_tel = []\n",
        "for eleme in all_df_list_new:\n",
        "  eleme['EndPoint'].fillna('', inplace=True)\n",
        "  declined_operation.append(eleme['EndPoint'].str.contains('decline').sum())\n",
        "declined_operation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsI_j80ISyMf",
        "outputId": "65913952-36ed-4be5-a0cb-025920655631"
      },
      "source": [
        "new_data_frame['EndPoint'].fillna('', inplace=True)\n",
        "list_operateurs_decline = []\n",
        "numero_tel = []\n",
        "for eleme in all_df_list_new:\n",
        "  eleme['EndPoint'].fillna('', inplace=True)\n",
        "  if eleme['EndPoint'].str.contains('decline').sum() > 0 :\n",
        "    list_operateurs_decline.append(eleme)\n",
        "    list_personnes_risque.append(eleme)\n",
        "\n",
        "print(len(list_operateurs_decline))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StfeMdUAf-1y"
      },
      "source": [
        "### recherce du nombre d'utilisateurs qui effectuent plusieurs achats (Lifestyle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Xpb7gUgJVv",
        "outputId": "8c74a38e-a7bf-4cd0-e000-69fc0d09b0c8"
      },
      "source": [
        "import statistics\n",
        "new_data_frame['EndPoint'].fillna('', inplace=True)\n",
        "lifestyle_operation = []\n",
        "for eleme in all_df_list_new:\n",
        "  eleme['EndPoint'].fillna('', inplace=True)\n",
        "  lifestyle_operation.append(eleme['EndPoint'].str.contains('lifestyle').sum())\n",
        "print(lifestyle_operation)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 8, 1, 0, 3, 1, 4, 19, 9, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 12, 8, 5, 1, 6, 10, 27, 0, 3, 6, 6, 5, 3, 3, 6, 1, 1, 5, 3, 7, 1, 2, 4, 1, 6, 4, 2, 1, 1, 3, 24, 1, 3, 1, 7, 62, 14, 0, 1, 3, 2, 5, 10, 4, 1, 1, 4, 23, 9, 2, 3, 0, 3, 2, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgw6XFCkYrVV",
        "outputId": "77dcd439-eacb-4024-a685-d0a6090c78ee"
      },
      "source": [
        "len(list_personnes_risque)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lP3N7q0pWX0b",
        "outputId": "54a0788f-a511-4145-c045-09e3524e0d31"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "bins = np.linspace(math.ceil(min(sum_operation)), \n",
        "                   math.floor(max(sum_operation)),\n",
        "                   20) # fixed number of bins\n",
        "\n",
        "plt.xlim([min(sum_operation)-5, max(sum_operation)+5])\n",
        "\n",
        "plt.hist(sum_operation, bins=bins, alpha=0.5)\n",
        "plt.title('Distribution des operations (fixed number of bins)')\n",
        "plt.xlabel('variable X (20 evenly spaced bins)')\n",
        "plt.ylabel('count')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}