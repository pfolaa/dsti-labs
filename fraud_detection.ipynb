{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOE46X/x8yV7hUd9PtvebxB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pfolaa/dsti-labs/blob/main/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfrluZHFeoJi",
        "outputId": "332b0ec1-7897-46e5-b1af-42c423e01350"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDZLS2SVpWRA"
      },
      "source": [
        "import os\n",
        "import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXUmQBdjjRSz"
      },
      "source": [
        "#cd /content/drive/MyDrive/datasets/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A647jZGTIVfV"
      },
      "source": [
        "## 1- Data acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM0BTYUsH0J7"
      },
      "source": [
        "###1.1- Get files from repository "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2XWYG1djOng"
      },
      "source": [
        "#!wget https://{bucket-name}.s3.eu-west-1.amazonaws.com/{file.zip}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ePlT65iHvE8"
      },
      "source": [
        "### 1.2 Extract zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY4poFTe_fiZ"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "#ZipFile(\"{file.zip}\").extractall('/content/drive/My Drive/datasets/')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Bife_AHmwn"
      },
      "source": [
        "### 1.3 Read all json files and insert into a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9kYyZKupaKF"
      },
      "source": [
        "import os,json\n",
        "import pandas as pd\n",
        "\n",
        "# read json file\n",
        "def read_Json_And_Insert_Into_CSV(path_file_json, file_csv, root_path):\n",
        "  os.makedirs(root_path, exist_ok=True) # créer toute l'aborescence du fichier, crée le chemin\n",
        "  # read all json files\n",
        "  for file_name in [file for file in os.listdir(path_file_json) if file.endswith('.json')]:\n",
        "    with open(path_file_json + file_name) as json_file:\n",
        "      data = json.load(json_file)\n",
        "      df = pd.DataFrame.from_records(data)\n",
        "\n",
        "  # convert file to csv\n",
        "  df.to_csv(f'{root_path}/{file_csv}', sep=';')\n",
        "  return df # return du fichier csv"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIL79akW0R8f"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9HdEw7t0Sjx"
      },
      "source": [
        "###NB: ne pas utiliser les memes noms de variables à l'intérieur des fonctions et à l'extérieur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCh5277VyUV4"
      },
      "source": [
        "path_json = '/content/drive/My Drive/datasets/nirra-log-bot/'\n",
        "root_csv = '/content/drive/My Drive/datasets/nirra-log-bot/csv'\n",
        "file_csv = 'file_name.csv'\n",
        "\n",
        "df_raw = read_Json_And_Insert_Into_CSV(path_json, file_csv, root_csv)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4q9nXruZEeS"
      },
      "source": [
        "df_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5hLbakIA9g"
      },
      "source": [
        "### Get total number of @ inside \"text\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1tAb3ZqNXxk",
        "outputId": "aff0390b-ca50-431c-8d4b-8565c6cd99ce"
      },
      "source": [
        " df_raw['text'].str.contains(\"@\").sum() # search total number of @ within text column"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h6pXkQwHaf_"
      },
      "source": [
        "### Test a slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOYCDMimN7Os"
      },
      "source": [
        "# slicing\n",
        "#df_raw[df_raw['text'].str.contains(\"@\")] # masque à l'intérieur des crochets"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7TN5BDtoPudJ",
        "outputId": "66f467bf-4ff8-4d4d-ef77-4a0b376e2e1b"
      },
      "source": [
        "df_raw[df_raw['text'] == None]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>subtype</th>\n",
              "      <th>text</th>\n",
              "      <th>ts</th>\n",
              "      <th>bot_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [type, subtype, text, ts, bot_id]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGScI9DACyVX"
      },
      "source": [
        "### Functions used in case of OKRA WEBHOOK, WALLET SUCCESS, SMS SUCCESS, SMS PAYLOAD Types request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CapeBj_Wqfkd"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "#text_okra_webhook = df_raw['text'][0]\n",
        "#text_wallet = df_raw['text'][841]\n",
        "#sms_success = df_raw['text'][12]\n",
        "#sms_payload = df_raw['text'][11]\n",
        "def parse_wallet_sms_payload_success(text_type_request):\n",
        "  ''' la fonction permet de parser les types de requete \"Okra WebHook\", \"Wallet success\", \n",
        "      \"SMS Success\" et SMS Payload en object json.\n",
        "      Elle prend en paramètre le text contenu dans le type de requete,\n",
        "      elle retourne un objet de type JSON.'''\n",
        "\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_type_request)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  s = json.loads(res)\n",
        "  out_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "\n",
        "  out_dump = json.dumps(out_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_wallet_success = json.loads(out_dump) # convertir le string json en object json.\n",
        "  return out_wallet_success\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f_3vBokI4W_"
      },
      "source": [
        "# Test Okra WebHook\n",
        "okra = parse_wallet_sms_payload_success(df_raw['text'][0])\n",
        "okra\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r42HQDd7IqD4"
      },
      "source": [
        "# Test Wallet Success\n",
        "wallet_success = parse_wallet_sms_payload_success(df_raw['text'][841])\n",
        "print(wallet_success.get('account_name'))\n",
        "print(wallet_success.get('account_number'))\n",
        "print(wallet_success.get('bvn'))\n",
        "print(wallet_success.get('requestSuccessful'))\n",
        "print(wallet_success.get('responseCode'))\n",
        "print(wallet_success.get('responseMessage'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vol_EjbkIdeu",
        "outputId": "7ed7074f-7f8e-4c55-9c6a-fea10e5e2b03"
      },
      "source": [
        "# Test SMS Sucess\n",
        "sms_succ = parse_wallet_sms_payload_success(df_raw['text'][12])\n",
        "sms_succ.get('response').get('cost ')\n",
        "sms_succ.get('response').get('status ')\n",
        "sms_succ.get('response').get('totalsent ')\n",
        "sms_succ.get('response')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost ': 2, 'status ': 'SUCCESS ', 'totalsent ': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIJQYyhvJfry"
      },
      "source": [
        "# Test SMS Payload\n",
        "sms_payload = parse_wallet_sms_payload_success(df_raw['text'][11])\n",
        "print(sms_payload)\n",
        "print(sms_payload.get('message'))\n",
        "print(sms_payload.get('phone'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxLQChIkYxVc"
      },
      "source": [
        "# Function to handle row with type request \"LEADWAY SUCCESS\" and concatenate rows\n",
        "### NB: faire un docstring (''' ''') pour chaque fonction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4c-G8ZBYp_Z"
      },
      "source": [
        "import re\n",
        "\n",
        "# la fonction doit prendre en paramètre quelque chose\n",
        "def parse_and_concatenate_Leadway_Success_Rows(df_raw):\n",
        "  '''Cette fonction permet de parser et de concatener le texte qui a LEADWAY SUCCESS\n",
        "     comme type de requete\n",
        "     elle prend comme paramètre un dataframe et retourne les valeurs suivantes:\n",
        "     - un texte concatené\n",
        "     - l'index de la 1ère ligne qu'on va utiliser ensuite pour l'effacer\n",
        "     - l'index de la dernière ligne qu'on va utiliser ensuite pour l'effacer '''\n",
        "\n",
        "  first_index = 0\n",
        "  last_index = 0\n",
        "  text_leadway_concat = ''\n",
        "  for index, row in df_raw.iterrows():  # boucler sur les colonnes de type text\n",
        "      text_row = row['text']  \n",
        "      if re.search('LEADWAY SUCCESS', text_row):\n",
        "        text_leadway_concat = text_row\n",
        "        first_index = index\n",
        "        first_index +=1\n",
        "        new_df = df_raw[first_index:]\n",
        "        for first_index, new_row in new_df.iterrows():\n",
        "          xxx = new_row['text']      \n",
        "          if not xxx.startswith('['):          \n",
        "            first_index += 1\n",
        "            text_leadway_concat = text_row + xxx       \n",
        "          elif xxx.startswith('['):\n",
        "            last_index = first_index-1\n",
        "            break\n",
        "\n",
        "\n",
        "  return text_leadway_concat, first_index, last_index\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFfztKeA8XgQ"
      },
      "source": [
        "leadway_succ, first_index_succ, last_index_succ = parse_and_concatenate_Leadway_Success_Rows(df_raw)\n",
        "leadway_succ, first_index_succ, last_index_succ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mliPyobDr4k"
      },
      "source": [
        "### Function to parse row Leadway Success to json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2FJ1cmnDl0A"
      },
      "source": [
        "# use this function when type request is LEADWAY SUCCESS\n",
        "import regex\n",
        "import json\n",
        "\n",
        "\n",
        "def parse_Leadway_Success_Row(text_leadway):\n",
        "  ''' fonction permettant de parser le text concatené pour le type de requet LEADWAY SUCCESS\n",
        "      elle retourner un dictionnaire.'''\n",
        "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*}')\n",
        "  resul_patt = pattern.findall(text_leadway)\n",
        "  resul_patt[0] = resul_patt[0].replace(\"\\\\\", \"\")\n",
        "  x = resul_patt[0].replace(\"make,\", \"\")\n",
        "  y = x.replace('\"\"makeName\"', '\"makeName\"')\n",
        "  z = json.loads(y)\n",
        "  vehicleMake = z.get('vehicleMake')\n",
        "  leadway_dict = {}\n",
        "  for element in vehicleMake:\n",
        "    leadway_dict[element['id']] = element['makeName']\n",
        "\n",
        "  return leadway_dict\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyu1DwSqdRrV",
        "outputId": "9d9c622f-1b05-4ecb-efbc-b1d4dbe11419"
      },
      "source": [
        "print(leadway_succ)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] - [\"[LEADWAY SUCCESS]:\",\"{\\\"errorMsg\\\":\\\"\\\",\\\"signature\\\":\\\"\\\",\\\"success\\\":true,\\\"vehicleMake\\\":[{\\\"id\\\":\\\"127\\\",\\\"makeName\\\":\\\"35CMB\\\"},{\\\"id\\\":\\\"152\\\",\\\"makeName\\\":\\\"AC ATUL\\\"},{\\\"id\\\":\\\"228\\\",\\\"makeName\\\":\\\"ACE\\\"},{\\\"id\\\":\\\"147\\\",\\\"makeName\\\":\\\"ACURA\\\"},{\\\"id\\\":\\\"8\\\",\\\"makeName\\\":\\\"ALPHA ROMEO\\\"},{\\\"id\\\":\\\"106\\\",\\\"makeName\\\":\\\"APACHE\\\"},{\\\"id\\\":\\\"210\\\",\\\"makeName\\\":\\\"ASHOK LEYLAND\\\"},{\\\"id\\\":\\\"80\\\",\\\"makeName\\\":\\\"ASTRA\\\"},{\\\"id\\\":\\\"3\\\",\\\"makeName\\\":\\\"AUDI\\\"},{\\\"id\\\":\\\"128\\\",\\\"makeName\\\":\\\"AUSTIN\\\"},{\\\"id\\\":\\\"109\\\",\\\"makeName\\\":\\\"BACK HOE\\\"},{\\\"id\\\":\\\"9\\\",\\\"makeName\\\":\\\"BADFORD\\\"},{\\\"id\\\":\\\"68\\\",\\\"makeName\\\":\\\"BAJAJ\\\"},{\\\"id\\\":\\\"218\\\",\\\"makeName\\\":\\\"BASUKI\\\"},{\\\"id\\\":\\\"248\\\",\\\"makeName\\\":\\\"BAW\\\"},{\\\"id\\\":\\\"244\\\",\\\"makeName\\\":\\\"BEDFORD\\\"},{\\\"id\\\":\\\"84\\\",\\\"makeName\\\":\\\"BEIBEN\\\"},{\\\"id\\\":\\\"195\\\",\\\"makeName\\\":\\\"BELL\\\"},{\\\"id\\\":\\\"174\\\",\\\"makeName\\\":\\\"BENTLEY\\\"},{\\\"id\\\":\\\"75\\\",\\\"makeName\\\":\\\"BHACHU\\\"},{\\\"id\\\":\\\"262\\\",\\\"makeName\\\":\\\"BIKEMASTER\\\"},{\\\"id\\\":\\\"92\\\",\\\"makeName\\\":\\\"BLUE BIRD\\\"},{\\\"id\\\":\\\"7\\\",\\\"makeName\\\":\\\"BMW\\\"},{\\\"id\\\":\\\"10\\\",\\\"makeName\\\":\\\"BOBCAT\\\"},{\\\"id\\\":\\\"290\\\",\\\"makeName\\\":\\\"BOVA\\\"},{\\\"id\\\":\\\"126\\\",\\\"makeName\\\":\\\"BPW\\\"},{\\\"id\\\":\\\"269\\\",\\\"makeName\\\":\\\"BRILLIANCE\\\"},{\\\"id\\\":\\\"182\\\",\\\"makeName\\\":\\\"BUICK\\\"},{\\\"id\\\":\\\"11\\\",\\\"makeName\\\":\\\"CADILLAC\\\"},{\\\"id\\\":\\\"12\\\",\\\"makeName\\\":\\\"CAM\\\"},{\\\"id\\\":\\\"284\\\",\\\"makeName\\\":\\\"CANTER FUSO\\\"},{\\\"id\\\":\\\"89\\\",\\\"makeName\\\":\\\"CAPTAIN\\\"},{\\\"id\\\":\\\"217\\\",\\\"makeName\\\":\\\"CARTER PEN\\\"},{\\\"id\\\":\\\"13\\\",\\\"makeName\\\":\\\"CAT\\\"},{\\\"id\\\":\\\"239\\\",\\\"makeName\\\":\\\"CATERPILLAR\\\"},{\\\"id\\\":\\\"254\\\",\\\"makeName\\\":\\\"CHANA STAR\\\"},{\\\"id\\\":\\\"142\\\",\\\"makeName\\\":\\\"CHANGAN\\\"},{\\\"id\\\":\\\"223\\\",\\\"makeName\\\":\\\"CHANGFENG\\\"},{\\\"id\\\":\\\"141\\\",\\\"makeName\\\":\\\"CHERRY\\\"},{\\\"id\\\":\\\"283\\\",\\\"makeName\\\":\\\"CHERY\\\"},{\\\"id\\\":\\\"14\\\",\\\"makeName\\\":\\\"CHEVROLET\\\"},{\\\"id\\\":\\\"15\\\",\\\"makeName\\\":\\\"CHRYSLER\\\"},{\\\"id\\\":\\\"16\\\",\\\"makeName\\\":\\\"CITROEN\\\"},{\\\"id\\\":\\\"104\\\",\\\"makeName\\\":\\\"CLAAS\\\"},{\\\"id\\\":\\\"17\\\",\\\"makeName\\\":\\\"CMC\\\"},{\\\"id\\\":\\\"181\\\",\\\"makeName\\\":\\\"COMMER\\\"},{\\\"id\\\":\\\"129\\\",\\\"makeName\\\":\\\"CPCD\\\"},{\\\"id\\\":\\\"275\\\",\\\"makeName\\\":\\\"DACIA\\\"},{\\\"id\\\":\\\"18\\\",\\\"makeName\\\":\\\"DAEWOO\\\"},{\\\"id\\\":\\\"138\\\",\\\"makeName\\\":\\\"DAF\\\"},{\\\"id\\\":\\\"19\\\",\\\"makeName\\\":\\\"DAIHATSU\\\"},{\\\"id\\\":\\\"131\\\",\\\"makeName\\\":\\\"DALIAN\\\"},{\\\"id\\\":\\\"190\\\",\\\"makeName\\\":\\\"DATSUN\\\"},{\\\"id\\\":\\\"191\\\",\\\"makeName\\\":\\\"DAVE\\\"},{\\\"id\\\":\\\"161\\\",\\\"makeName\\\":\\\"DAYLONG\\\"},{\\\"id\\\":\\\"99\\\",\\\"makeName\\\":\\\"DAYUN\\\"},{\\\"id\\\":\\\"158\\\",\\\"makeName\\\":\\\"DEGAB\\\"},{\\\"id\\\":\\\"179\\\",\\\"makeName\\\":\\\"DENNIS\\\"},{\\\"id\\\":\\\"150\\\",\\\"makeName\\\":\\\"DENSTAR\\\"},{\\\"id\\\":\\\"216\\\",\\\"makeName\\\":\\\"DFAC\\\"},{\\\"id\\\":\\\"270\\\",\\\"makeName\\\":\\\"DFM\\\"},{\\\"id\\\":\\\"243\\\",\\\"makeName\\\":\\\"DIAMOND REO\\\"},{\\\"id\\\":\\\"183\\\",\\\"makeName\\\":\\\"DODGE\\\"},{\\\"id\\\":\\\"74\\\",\\\"makeName\\\":\\\"DOLL\\\"},{\\\"id\\\":\\\"88\\\",\\\"makeName\\\":\\\"DONGFENG\\\"},{\\\"id\\\":\\\"132\\\",\\\"makeName\\\":\\\"DOOSAN\\\"},{\\\"id\\\":\\\"20\\\",\\\"makeName\\\":\\\"DUCATI\\\"},{\\\"id\\\":\\\"280\\\",\\\"makeName\\\":\\\"EAGLE\\\"},{\\\"id\\\":\\\"297\\\",\\\"makeName\\\":\\\"EFR\\\"},{\\\"id\\\":\\\"21\\\",\\\"makeName\\\":\\\"EICHER\\\"},{\\\"id\\\":\\\"110\\\",\\\"makeName\\\":\\\"ELITE\\\"},{\\\"id\\\":\\\"249\\\",\\\"makeName\\\":\\\"ENGLON\\\"},{\\\"id\\\":\\\"250\\\",\\\"makeName\\\":\\\"ENGLON \\\"},{\\\"id\\\":\\\"240\\\",\\\"makeName\\\":\\\"E-ONE\\\"},{\\\"id\\\":\\\"295\\\",\\\"makeName\\\":\\\"ETEFA\\\"},{\\\"id\\\":\\\"186\\\",\\\"makeName\\\":\\\"EVERLAST\\\"},{\\\"id\\\":\\\"176\\\",\\\"makeName\\\":\\\"FALCON\\\"},{\\\"id\\\":\\\"70\\\",\\\"makeName\\\":\\\"FAW\\\"},{\\\"id\\\":\\\"22\\\",\\\"makeName\\\":\\\"FIAT\\\"},{\\\"id\\\":\\\"256\\\",\\\"makeName\\\":\\\"FIORI\\\"},{\\\"id\\\":\\\"133\\\",\\\"makeName\\\":\\\"FLATBED\\\"},{\\\"id\\\":\\\"23\\\",\\\"makeName\\\":\\\"FORD\\\"},{\\\"id\\\":\\\"222\\\",\\\"makeName\\\":\\\"FORLAND\\\"},{\\\"id\\\":\\\"24\\\",\\\"makeName\\\":\\\"FOTON\\\"},{\\\"id\\\":\\\"148\\\",\\\"makeName\\\":\\\"FRAJEND\\\"},{\\\"id\\\":\\\"170\\\",\\\"makeName\\\":\\\"FREIGHTLINER\\\"},{\\\"id\\\":\\\"151\\\",\\\"makeName\\\":\\\"FUSO\\\"},{\\\"id\\\":\\\"164\\\",\\\"makeName\\\":\\\"GAC\\\"},{\\\"id\\\":\\\"298\\\",\\\"makeName\\\":\\\"Geely\\\"},{\\\"id\\\":\\\"226\\\",\\\"makeName\\\":\\\"GEELY\\\"},{\\\"id\\\":\\\"213\\\",\\\"makeName\\\":\\\"GENIE \\\"},{\\\"id\\\":\\\"277\\\",\\\"makeName\\\":\\\"GENLYON\\\"},{\\\"id\\\":\\\"162\\\",\\\"makeName\\\":\\\"GMC\\\"},{\\\"id\\\":\\\"268\\\",\\\"makeName\\\":\\\"GOLDEN DRAGON\\\"},{\\\"id\\\":\\\"291\\\",\\\"makeName\\\":\\\"GONOW\\\"},{\\\"id\\\":\\\"286\\\",\\\"make,\\\"makeName\\\":\\\"NISSAN\\\"},{\\\"id\\\":\\\"296\\\",\\\"makeName\\\":\\\"OLDSMOBILE\\\"},{\\\"id\\\":\\\"42\\\",\\\"makeName\\\":\\\"OPEL\\\"},{\\\"id\\\":\\\"289\\\",\\\"makeName\\\":\\\"PETERBILT\\\"},{\\\"id\\\":\\\"43\\\",\\\"makeName\\\":\\\"PEUGEOT\\\"},{\\\"id\\\":\\\"105\\\",\\\"makeName\\\":\\\"PIAGGIO\\\"},{\\\"id\\\":\\\"261\\\",\\\"makeName\\\":\\\"POLARSUN\\\"},{\\\"id\\\":\\\"159\\\",\\\"makeName\\\":\\\"PONTIAC\\\"},{\\\"id\\\":\\\"44\\\",\\\"makeName\\\":\\\"PORSCHE\\\"},{\\\"id\\\":\\\"266\\\",\\\"makeName\\\":\\\"PRESIDENT\\\"},{\\\"id\\\":\\\"211\\\",\\\"makeName\\\":\\\"PROTON\\\"},{\\\"id\\\":\\\"253\\\",\\\"makeName\\\":\\\"QINGQI\\\"},{\\\"id\\\":\\\"246\\\",\\\"makeName\\\":\\\"QIPAI\\\"},{\\\"id\\\":\\\"157\\\",\\\"makeName\\\":\\\"QLINK\\\"},{\\\"id\\\":\\\"118\\\",\\\"makeName\\\":\\\"QUON\\\"},{\\\"id\\\":\\\"45\\\",\\\"makeName\\\":\\\"RANDON\\\"},{\\\"id\\\":\\\"47\\\",\\\"makeName\\\":\\\"RENAULT\\\"},{\\\"id\\\":\\\"292\\\",\\\"makeName\\\":\\\"Robinson\\\"},{\\\"id\\\":\\\"197\\\",\\\"makeName\\\":\\\"ROLLS-ROYCE\\\"},{\\\"id\\\":\\\"48\\\",\\\"makeName\\\":\\\"ROVER\\\"},{\\\"id\\\":\\\"207\\\",\\\"makeName\\\":\\\"ROYAL\\\"},{\\\"id\\\":\\\"49\\\",\\\"makeName\\\":\\\"SAAB\\\"},{\\\"id\\\":\\\"130\\\",\\\"makeName\\\":\\\"SACHS\\\"},{\\\"id\\\":\\\"50\\\",\\\"makeName\\\":\\\"SAILORMEIYA\\\"},{\\\"id\\\":\\\"72\\\",\\\"makeName\\\":\\\"SAME\\\"},{\\\"id\\\":\\\"194\\\",\\\"makeName\\\":\\\"SANY\\\"},{\\\"id\\\":\\\"274\\\",\\\"makeName\\\":\\\"SATURN\\\"},{\\\"id\\\":\\\"51\\\",\\\"makeName\\\":\\\"SCANIA\\\"},{\\\"id\\\":\\\"232\\\",\\\"makeName\\\":\\\"SCHWING\\\"},{\\\"id\\\":\\\"172\\\",\\\"makeName\\\":\\\"SCION\\\"},{\\\"id\\\":\\\"221\\\",\\\"makeName\\\":\\\"SEAT\\\"},{\\\"id\\\":\\\"245\\\",\\\"makeName\\\":\\\"SENKE\\\"},{\\\"id\\\":\\\"52\\\",\\\"makeName\\\":\\\"SHACMAN\\\"},{\\\"id\\\":\\\"111\\\",\\\"makeName\\\":\\\"SHANTUI\\\"},{\\\"id\\\":\\\"119\\\",\\\"makeName\\\":\\\"SHENZEN\\\"},{\\\"id\\\":\\\"100\\\",\\\"makeName\\\":\\\"SHINERAY\\\"},{\\\"id\\\":\\\"215\\\",\\\"makeName\\\":\\\"SHIRORO\\\"},{\\\"id\\\":\\\"171\\\",\\\"makeName\\\":\\\"SINO\\\"},{\\\"id\\\":\\\"168\\\",\\\"makeName\\\":\\\"SINOKI SUPRA\\\"},{\\\"id\\\":\\\"53\\\",\\\"makeName\\\":\\\"SINOTRUCK\\\"},{\\\"id\\\":\\\"54\\\",\\\"makeName\\\":\\\"SKODA\\\"},{\\\"id\\\":\\\"108\\\",\\\"makeName\\\":\\\"SKYGO\\\"},{\\\"id\\\":\\\"55\\\",\\\"makeName\\\":\\\"SMART\\\"},{\\\"id\\\":\\\"263\\\",\\\"makeName\\\":\\\"SONLINK\\\"},{\\\"id\\\":\\\"192\\\",\\\"makeName\\\":\\\"SOYAT\\\"},{\\\"id\\\":\\\"56\\\",\\\"makeName\\\":\\\"SSANGYONG\\\"},{\\\"id\\\":\\\"145\\\",\\\"makeName\\\":\\\"STALLION\\\"},{\\\"id\\\":\\\"86\\\",\\\"makeName\\\":\\\"STAR\\\"},{\\\"id\\\":\\\"209\\\",\\\"makeName\\\":\\\"STERLING\\\"},{\\\"id\\\":\\\"281\\\",\\\"makeName\\\":\\\"STEYR\\\"},{\\\"id\\\":\\\"95\\\",\\\"makeName\\\":\\\"STO\\\"},{\\\"id\\\":\\\"57\\\",\\\"makeName\\\":\\\"SUBARU\\\"},{\\\"id\\\":\\\"272\\\",\\\"makeName\\\":\\\"SUPER GALLANT\\\"},{\\\"id\\\":\\\"251\\\",\\\"makeName\\\":\\\"SUPER POWER\\\"},{\\\"id\\\":\\\"153\\\",\\\"makeName\\\":\\\"SUPRA MARS\\\"},{\\\"id\\\":\\\"58\\\",\\\"makeName\\\":\\\"SUZUKI\\\"},{\\\"id\\\":\\\"264\\\",\\\"makeName\\\":\\\"TAFE TRACTOR \\\"},{\\\"id\\\":\\\"193\\\",\\\"makeName\\\":\\\"TANADO\\\"},{\\\"id\\\":\\\"59\\\",\\\"makeName\\\":\\\"TATA\\\"},{\\\"id\\\":\\\"198\\\",\\\"makeName\\\":\\\"TEC\\\"},{\\\"id\\\":\\\"231\\\",\\\"makeName\\\":\\\"TEREX\\\"},{\\\"id\\\":\\\"185\\\",\\\"makeName\\\":\\\"TIANMA\\\"},{\\\"id\\\":\\\"60\\\",\\\"makeName\\\":\\\"TIGO\\\"},{\\\"id\\\":\\\"81\\\",\\\"makeName\\\":\\\"TLD\\\"},{\\\"id\\\":\\\"1\\\",\\\"makeName\\\":\\\"TOYOTA\\\"},{\\\"id\\\":\\\"73\\\",\\\"makeName\\\":\\\"TRACTOR\\\"},{\\\"id\\\":\\\"87\\\",\\\"makeName\\\":\\\"TRAIL KING\\\"},{\\\"id\\\":\\\"77\\\",\\\"makeName\\\":\\\"TRANSTRAILER\\\"},{\\\"id\\\":\\\"134\\\",\\\"makeName\\\":\\\"TRIUMPH\\\"},{\\\"id\\\":\\\"149\\\",\\\"makeName\\\":\\\"TRUMPCHI GAC\\\"},{\\\"id\\\":\\\"202\\\",\\\"makeName\\\":\\\"TUG\\\"},{\\\"id\\\":\\\"78\\\",\\\"makeName\\\":\\\"TVS\\\"},{\\\"id\\\":\\\"165\\\",\\\"makeName\\\":\\\"TWINCO\\\"},{\\\"id\\\":\\\"69\\\",\\\"makeName\\\":\\\"UM\\\"},{\\\"id\\\":\\\"97\\\",\\\"makeName\\\":\\\"VALTRA\\\"},{\\\"id\\\":\\\"61\\\",\\\"makeName\\\":\\\"VAUXHALL\\\"},{\\\"id\\\":\\\"62\\\",\\\"makeName\\\":\\\"VOLKSWAGEN\\\"},{\\\"id\\\":\\\"63\\\",\\\"makeName\\\":\\\"VOLVO\\\"},{\\\"id\\\":\\\"237\\\",\\\"makeName\\\":\\\"VPG\\\"},{\\\"id\\\":\\\"278\\\",\\\"makeName\\\":\\\"Wrangler\\\"},{\\\"id\\\":\\\"64\\\",\\\"makeName\\\":\\\"WUHAN SHENJUN\\\"},{\\\"id\\\":\\\"65\\\",\\\"makeName\\\":\\\"YAMAHA\\\"},{\\\"id\\\":\\\"96\\\",\\\"makeName\\\":\\\"YATIAN\\\"},{\\\"id\\\":\\\"180\\\",\\\"makeName\\\":\\\"YORK\\\"},{\\\"id\\\":\\\"294\\\",\\\"makeName\\\":\\\"YUEJIN\\\"},{\\\"id\\\":\\\"155\\\",\\\"makeName\\\":\\\"YUTONG\\\"},{\\\"id\\\":\\\"173\\\",\\\"makeName\\\":\\\"ZAHAV\\\"},{\\\"id\\\":\\\"260\\\",\\\"makeName\\\":\\\"ZHEJIANG XINCHAI\\\"},{\\\"id\\\":\\\"175\\\",\\\"makeName\\\":\\\"ZHONGTONG\\\"},{\\\"id\\\":\\\"113\\\",\\\"makeName\\\":\\\"ZOOMLION\\\"},{\\\"id\\\":\\\"247\\\",\\\"makeName\\\":\\\"ZOTYE\\\"}]}\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-K_HcgpL0Iv"
      },
      "source": [
        "# TEST LEADWAY SUCCESS\n",
        "resultat_leadway = parse_Leadway_Success_Row(leadway_succ)\n",
        "\n",
        "for i in resultat_leadway:\n",
        "  print(resultat_leadway.get(i))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZfl792oBMyw",
        "outputId": "1a2f8b66-7bd5-4b80-ae92-d6f8b8118cfa"
      },
      "source": [
        "2356 in df_raw.index"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho5dPdBwml27"
      },
      "source": [
        "### Function to handle log level \"Error\"\n",
        "NB: faire un docstring (''' ''') pour chaque fonction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLMS5PrDoPIV"
      },
      "source": [
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_Error_Row(error_row):\n",
        "  error_row = error_row.replace('\"', \"'\")\n",
        "  pattern = regex.compile(r\"{?[a-z :A-Z 0-9\\\\,=_`']+selfie\")\n",
        "  resul_patt = pattern.findall(error_row)\n",
        "  res = resul_patt[0].replace(\"\\\\\", \" \")\n",
        "  res = res.replace(\"'name'\", \"name\").replace(\"`\", \"\").replace(\"'18'\", \"18\").replace(\"'monthly'\", \"monthly\")\n",
        "  res = res+'\"}'\n",
        "  res = res.replace(\"'\", '\"')\n",
        "  s = json.loads(res)\n",
        "  out_error_dict = {} # dictionnary vide\n",
        "  for key, value in s.items():\n",
        "    out_error_dict[key.strip()] = value # à la clé on passe chaque valeur, strip() enlève les espaces au début et à la fin.\n",
        "\n",
        "  out_error_dump = json.dumps(out_error_dict) # input est un dictionnaire et ça retourne un json sous forme string\n",
        "  out_error_text = json.loads(out_error_dump) # convertir le string json en object json.\n",
        "  return out_error_text\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RZvPvv3FgyK"
      },
      "source": [
        "error_text = parse_Error_Row(df_raw['text'][2355])\n",
        "print(error_text)\n",
        "print(error_text.get('code'))\n",
        "print(error_text.get('errno'))\n",
        "print(error_text.get('sqlMessage'))\n",
        "print(error_text.get('sqlState'))\n",
        "print(error_text.get('index'))\n",
        "print(error_text.get('sql'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9EAlNYIv5x"
      },
      "source": [
        "### Function to convert data to timestamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd-prG9NMlJz"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# function to convert date to Timestamp\n",
        "def convertToTimestamp(str):\n",
        "  element = datetime.datetime.strptime(str,\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "  return datetime.datetime.timestamp(element)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-rZUfpUM3lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a33c5d6-9878-40a2-d42b-9ea25a65a212"
      },
      "source": [
        "timestamp = convertToTimestamp('2021-09-05T07:03:55.223Z')\n",
        "timestamp"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1630825435.223"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8TrJS3NHJ6x"
      },
      "source": [
        "## 2 Data model\n",
        "### 2.1 Parse rows of dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "585dRkFQPUbB"
      },
      "source": [
        "### 2.1.1 créer un dictionnary pour les regex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88lZf2qqvQag"
      },
      "source": [
        "type_request_dictionnary = {}\n",
        "regex_list_api_request = []\n",
        "regex_list_api_request.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_api_request.append('/[/a-z 0-9?=&;/_A-Z+]+')\n",
        "regex_list_api_request.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_api_request.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['API REQUEST'] = regex_list_api_request\n",
        "\n",
        "regex_list_client_mobile = []\n",
        "regex_list_client_mobile.append('[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
        "regex_list_client_mobile.append('(\\d{4})-(\\d\\d)-(\\d\\d)T(\\d\\d):(\\d\\d):(\\d\\d).(\\d{3})*[a-zA-Z]')\n",
        "regex_list_client_mobile.append('[0-9]+')\n",
        "\n",
        "type_request_dictionnary['CLIENT MOBILE LOGIN'] = regex_list_client_mobile\n",
        "\n",
        "type_request_dictionnary['SMS PAYLOAD'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['SMS SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['WALLET SUCCESS'] = '\\{(?:[^{}]|(?R))*}'\n",
        "type_request_dictionnary['LEADWAY SUCCESS'] = '\\{(?:[^{}]|(?R))*}'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceqzAG_lPsE7"
      },
      "source": [
        "### 2.1.2 Functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AJ6V9HulbOq"
      },
      "source": [
        "### Handle DataFrame Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-IUROmk7Bh"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_error(df_):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  error_code_col = []\n",
        "  error_number_col = []\n",
        "  error_sql_message_col = []\n",
        "  error_sql_state_col = []\n",
        "  error_index_col = []\n",
        "  error_sql_col = []\n",
        "\n",
        "  \n",
        "  list_column_none_level_log_error = []\n",
        "  list_column_none = [message_sms_payload_col, totalsent_col, cost_col, status_col, email_col,\n",
        "                      phone_Col, endpoint_Col, date_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                      responseCode_col, account_name_col, account_number_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col,\n",
        "                    error_code_col, error_number_col, error_sql_message_col, error_sql_state_col, \n",
        "                    error_index_col, error_sql_col]\n",
        "\n",
        "  for index, row in df_.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "    \n",
        "    if re.search('error', str_text):\n",
        "        log_level = re.search('error', str_text)\n",
        "          \n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)\n",
        "\n",
        "        if re.search('LOAN ERROR', str_text):\n",
        "            type_of_request = re.search('LOAN ERROR', str_text)\n",
        "            loan_error = parse_Error_Row(str_text) \n",
        "            try:\n",
        "              error_code_col.append(loan_error.get('code'))\n",
        "              print(error_code_col)\n",
        "            except AttributeError:\n",
        "              error_code_col.append(None)\n",
        "            try:\n",
        "              print(loan_error.get('errno'))\n",
        "              error_number_col.append(loan_error.get('errno'))\n",
        "              print('error number :')\n",
        "              print(error_number_col)\n",
        "            except AttributeError:\n",
        "              error_number_col.append(None)\n",
        "            try:\n",
        "              error_sql_message_col.append(loan_error.get('sqlMessage'))\n",
        "            except AttributeError:\n",
        "              error_sql_message_col.append(None)\n",
        "            try:\n",
        "              error_sql_state_col.append(loan_error.get('sqlState'))\n",
        "            except AttributeError:\n",
        "              error_sql_state_col.append(None)\n",
        "            try:\n",
        "              error_index_col.append(loan_error.get('index'))\n",
        "            except AttributeError:\n",
        "              error_index_col.append(None)\n",
        "            try:\n",
        "              error_sql_col.append(loan_error.get('sql'))\n",
        "            except AttributeError:\n",
        "              error_sql_col.append(None)       \n",
        "\n",
        "            try:\n",
        "                type_request_col.append(type_of_request.group(0))\n",
        "            except AttributeError:\n",
        "                type_request_col.append(None)\n",
        "\n",
        "            for p in range(len(list_column_none)):\n",
        "              list_column_none[p].append(None)\n",
        "  \n",
        "  \n",
        "  #for x in range(len(list_all_colum)):\n",
        "   # print(len(list_all_colum[x]))\n",
        "  \n",
        "  df_['Type_Request'] = type_request_col\n",
        "  df_['Phone_Number'] = phone_Col\n",
        "  df_['Date'] = date_col\n",
        "  df_['EndPoint'] = endpoint_Col\n",
        "  df_['Log_Level'] = log_level_col\n",
        "  df_['Email'] = email_col\n",
        "  df_['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_['Total Sent'] = totalsent_col\n",
        "  df_['Cost'] = cost_col\n",
        "  df_['Status'] = status_col\n",
        "  df_['Account Number'] = account_number_col\n",
        "  df_['Account Name'] = account_name_col\n",
        "  df_['BVN'] = bvn_col\n",
        "  df_['Request Successful'] = requestSuccessful_col\n",
        "  df_['Response Message'] = responseMessage_col\n",
        "  df_['Response Code'] = responseCode_col\n",
        "  df_['Error Code'] = error_code_col\n",
        "  df_['Error Number'] = error_number_col\n",
        "  df_['Error Sql Message'] = error_sql_message_col\n",
        "  df_['Error Sql State'] = error_sql_state_col\n",
        "  df_['Error Index'] = error_index_col\n",
        "  df_['Error Sql'] = error_sql_col\n",
        "\n",
        "\n",
        "  return df_"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-o576_eO32"
      },
      "source": [
        "### Handle DataFrame for error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3poKQQZa6cA0"
      },
      "source": [
        "df_error = df_raw[df_raw['text'].str.contains('LOAN ERROR')]\n",
        "resutat_error = parse_row_error(df_error)\n",
        "resutat_error.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK5QuIgk9xxo"
      },
      "source": [
        "#df_raw = df_raw.drop(2355)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u--eSd8pBL03"
      },
      "source": [
        "df_raw.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B2AIKGMEuuG"
      },
      "source": [
        "### Handle DataFrame for API REQUEST Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0d5QsJ6Db5s"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_api_request(df_api_request):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_api_request = []\n",
        "  list_column_none_api_request = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, account_number_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_api_request.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                \n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][0], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "                               \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)               \n",
        "                try:\n",
        "                  email_col.append(phone_or_email_api_req.group(0)) # add email inside email column\n",
        "                  phone_Col.append(None)  # in this case there is no phone number\n",
        "                except AttributeError:\n",
        "                  email_col.append(None)\n",
        "                try:\n",
        "                  endpoint_Col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_Col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "              \n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('API REQUEST', str_text):\n",
        "                type_of_request = re.search('API REQUEST', str_text)                            \n",
        "                # extract a phone number for API REQUEST\n",
        "                phone_or_email_api_req = re.search(type_request_dictionnary['API REQUEST'][3], str_text)                              \n",
        "                endpoint = re.search(type_request_dictionnary['API REQUEST'][1], str_text)\n",
        "                pattern = type_request_dictionnary['API REQUEST'][2]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for i in range(len(list_column_none_api_request)):\n",
        "                  list_column_none_api_request[i].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_api_req.group(0)) # add phone number inside phone number column\n",
        "                  email_col.append(None) # in this case there is no email address\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  endpoint_Col.append(endpoint.group(0)) # add endpoint inside endpoint column\n",
        "                except AttributeError:\n",
        "                  endpoint_Col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None)\n",
        "\n",
        "  df_api_request['Type_Request'] = type_request_col\n",
        "  df_api_request['Phone_Number'] = phone_Col\n",
        "  df_api_request['Date'] = date_col\n",
        "  df_api_request['EndPoint'] = endpoint_Col\n",
        "  df_api_request['Log_Level'] = log_level_col\n",
        "  df_api_request['Email'] = email_col\n",
        "  df_api_request['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_api_request['Total Sent'] = totalsent_col\n",
        "  df_api_request['Cost'] = cost_col\n",
        "  df_api_request['Status'] = status_col\n",
        "  df_api_request['Account Number'] = account_number_col\n",
        "  df_api_request['Account Name'] = account_name_col\n",
        "  df_api_request['BVN'] = bvn_col\n",
        "  df_api_request['Request Successful'] = requestSuccessful_col\n",
        "  df_api_request['Response Message'] = responseMessage_col\n",
        "  df_api_request['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_api_request"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHNYGxLEpl9"
      },
      "source": [
        "df_api_request_ = df_raw[df_raw['text'].str.contains('API REQUEST')]\n",
        "resutat_df_api = parse_row_api_request(df_api_request_)\n",
        "resutat_df_api.head(10)\n",
        "resutat_df_api.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBE4JmynFp2_"
      },
      "source": [
        "### Handle DataFrame for Client Mobile Login Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnVrzUqSFpV1"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_client_mobile_login(df_client_mob):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_client_mobile = []\n",
        "  list_column_none_client_mobile = [message_sms_payload_col, totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, endpoint_Col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_client_mob.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)        \n",
        "        # check if the row contains an email address \n",
        "        # pour tous les types request créer un dictionnaire dans lequel mapper\n",
        "        # key = type de request et value = les regex définis\n",
        "        # pour chaque condition IF créer une liste de colonnes auxquelles affecter None\n",
        "        if 'mailto' in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text):   # CLIENT MOBILE LOGIN with email address\n",
        "                  type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                  # extract address email for CLIENT MOBILE LOGIN\n",
        "                  phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][0], str_text)                               \n",
        "                  pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                  datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                  datematcher = datepattern.search(str_text)  # extract date for CLIENT MOBILE LOGIN type request\n",
        "                  \n",
        "                  for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0)) # add type request inside type request column\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None) \n",
        "                  try:\n",
        "                    email_col.append(phone_or_email_client_mobile.group(0)) # add email inside email column\n",
        "                    phone_Col.append(None)  # in this case there is no phone number\n",
        "                  except AttributeError:\n",
        "                    email_col.append(None)\n",
        "                  try:\n",
        "                    date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                  except AttributeError:\n",
        "                    date_col.append(None)\n",
        "\n",
        "        elif 'mailto' not in str_text:\n",
        "            if re.search('CLIENT MOBILE LOGIN', str_text): # when type request is CLIENT MOBILE LOGIN, there is no EndPoint\n",
        "                type_of_request = re.search('CLIENT MOBILE LOGIN', str_text)\n",
        "                # extract a phone number for CLIENT MOBILE LOGIN\n",
        "                phone_or_email_client_mobile = re.search(type_request_dictionnary['CLIENT MOBILE LOGIN'][2], str_text)                  \n",
        "                pattern = type_request_dictionnary['CLIENT MOBILE LOGIN'][1]\n",
        "                datepattern = re.compile(\"(?:%s)\"%(pattern))\n",
        "                datematcher = datepattern.search(str_text)  # extract date\n",
        "\n",
        "                for j in range(len(list_column_none_client_mobile)):\n",
        "                    list_column_none_client_mobile[j].append(None)\n",
        "\n",
        "                try:\n",
        "                  phone_Col.append(phone_or_email_client_mobile.group(0))\n",
        "                  email_col.append(None)\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  date_col.append(convertToTimestamp(datematcher.group(0))) # convert date to timestamp and add it inside date column\n",
        "                except AttributeError:\n",
        "                  date_col.append(None) \n",
        "\n",
        "  df_client_mob['Type_Request'] = type_request_col\n",
        "  df_client_mob['Phone_Number'] = phone_Col\n",
        "  df_client_mob['Date'] = date_col\n",
        "  df_client_mob['EndPoint'] = endpoint_Col\n",
        "  df_client_mob['Log_Level'] = log_level_col\n",
        "  df_client_mob['Email'] = email_col\n",
        "  df_client_mob['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_client_mob['Total Sent'] = totalsent_col\n",
        "  df_client_mob['Cost'] = cost_col\n",
        "  df_client_mob['Status'] = status_col\n",
        "  df_client_mob['Account Number'] = account_number_col\n",
        "  df_client_mob['Account Name'] = account_name_col\n",
        "  df_client_mob['BVN'] = bvn_col\n",
        "  df_client_mob['Request Successful'] = requestSuccessful_col\n",
        "  df_client_mob['Response Message'] = responseMessage_col\n",
        "  df_client_mob['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_client_mob"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTlHywpVGsw4"
      },
      "source": [
        "df_client_mobile_login = df_raw[df_raw['text'].str.contains('CLIENT MOBILE LOGIN')]\n",
        "resutat_df_client_mobile_login = parse_row_client_mobile_login(df_client_mobile_login)\n",
        "resutat_df_client_mobile_login.head()\n",
        "resutat_df_client_mobile_login.info()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5iY2LGHekm"
      },
      "source": [
        "### Handle DataFrame for SMS PAYLOAD Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Iqpe8gHore"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_payload_function(df_sms_payload):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_payload = []\n",
        "  list_column_none_sms_payload = [totalsent_col, cost_col, status_col,\n",
        "                                  account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                  responseCode_col, account_name_col, email_col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_payload.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS PAYLOAD', str_text):\n",
        "                type_of_request = re.search('SMS PAYLOAD', str_text)            \n",
        "                sms_payload = parse_wallet_sms_payload_success(str_text)               \n",
        "                for l in range(len(list_column_none_sms_payload)):\n",
        "                    list_column_none_sms_payload[l].append(None)             \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:\n",
        "                  phone_Col.append(sms_payload.get('phone'))\n",
        "                except AttributeError:\n",
        "                  phone_Col.append(None)\n",
        "                try:\n",
        "                  message_sms_payload_col.append(sms_payload.get('message'))\n",
        "                except AttributeError:\n",
        "                  message_sms_payload_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_sms_payload['Type_Request'] = type_request_col\n",
        "  df_sms_payload['Phone_Number'] = phone_Col\n",
        "  df_sms_payload['Date'] = date_col\n",
        "  df_sms_payload['EndPoint'] = endpoint_Col\n",
        "  df_sms_payload['Log_Level'] = log_level_col\n",
        "  df_sms_payload['Email'] = email_col\n",
        "  df_sms_payload['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_payload['Total Sent'] = totalsent_col\n",
        "  df_sms_payload['Cost'] = cost_col\n",
        "  df_sms_payload['Status'] = status_col\n",
        "  df_sms_payload['Account Number'] = account_number_col\n",
        "  df_sms_payload['Account Name'] = account_name_col\n",
        "  df_sms_payload['BVN'] = bvn_col\n",
        "  df_sms_payload['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_payload['Response Message'] = responseMessage_col\n",
        "  df_sms_payload['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_payload\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etb-rPaJHMZ"
      },
      "source": [
        "df_sms_payload_ = df_raw[df_raw['text'].str.contains('SMS PAYLOAD')]\n",
        "resutat_df_sms_payload = parse_row_sms_payload_function(df_sms_payload_)\n",
        "resutat_df_sms_payload.head()\n",
        "#resutat_df_sms_payload.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz-7pflyJ_Fs"
      },
      "source": [
        "### Handle DataFrame for SMS Success Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJG8_sMYKDKw"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_sms_success_function(df_sms_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  \n",
        "  list_column_none_sms_success = []\n",
        "  list_column_none_sms_success = [message_sms_payload_col, account_number_col, bvn_col, requestSuccessful_col, \n",
        "                                  responseMessage_col, responseCode_col, account_name_col, email_col, \n",
        "                                  phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_sms_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('SMS SUCCESS', str_text): \n",
        "                type_of_request = re.search('SMS SUCCESS', str_text)\n",
        "                sms_success = parse_wallet_sms_payload_success(str_text)                \n",
        "                for m in range(len(list_column_none_sms_success)):\n",
        "                    list_column_none_sms_success[m].append(None) \n",
        "           \n",
        "                try:\n",
        "                  type_request_col.append(type_of_request.group(0))\n",
        "                except AttributeError:\n",
        "                  type_request_col.append(None)\n",
        "                try:                 \n",
        "                  totalsent_col.append(sms_success.get('response').get('totalsent '))\n",
        "                except AttributeError:\n",
        "                  totalsent_col.append(None)\n",
        "                try:                 \n",
        "                  cost_col.append(sms_success.get('response').get('cost '))\n",
        "                except AttributeError:\n",
        "                  cost_col.append(None)\n",
        "                try:                 \n",
        "                  status_col.append(sms_success.get('response').get('status '))\n",
        "                except AttributeError:\n",
        "                  status_col.append(None)\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)    \n",
        "\n",
        "  df_sms_success['Type_Request'] = type_request_col\n",
        "  df_sms_success['Phone_Number'] = phone_Col\n",
        "  df_sms_success['Date'] = date_col\n",
        "  df_sms_success['EndPoint'] = endpoint_Col\n",
        "  df_sms_success['Log_Level'] = log_level_col\n",
        "  df_sms_success['Email'] = email_col\n",
        "  df_sms_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_sms_success['Total Sent'] = totalsent_col\n",
        "  df_sms_success['Cost'] = cost_col\n",
        "  df_sms_success['Status'] = status_col\n",
        "  df_sms_success['Account Number'] = account_number_col\n",
        "  df_sms_success['Account Name'] = account_name_col\n",
        "  df_sms_success['BVN'] = bvn_col\n",
        "  df_sms_success['Request Successful'] = requestSuccessful_col\n",
        "  df_sms_success['Response Message'] = responseMessage_col\n",
        "  df_sms_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_sms_success\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWOAd_5KmGM"
      },
      "source": [
        "df_sms_success_ = df_raw[df_raw['text'].str.contains('SMS SUCCESS')]\n",
        "resutat_df_sms_success = parse_row_sms_success_function(df_sms_success_)\n",
        "resutat_df_sms_success.head()\n",
        "#resutat_df_sms_success.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMxkpxxcK72K"
      },
      "source": [
        "### Handle DataFrame for WALLET SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-XB7evJLGvD"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_wallet_success_function(df_wallet_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_wallet_success = []\n",
        "  list_column_none_wallet_success = [totalsent_col, message_sms_payload_col, cost_col, status_col, \n",
        "                                     email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "  \n",
        "  for index, row in df_wallet_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('WALLET SUCCESS', str_text):\n",
        "                  wallet_success = parse_wallet_sms_payload_success(str_text)\n",
        "                  type_of_request = re.search('WALLET SUCCESS', str_text)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                  try:\n",
        "                    account_number_col.append(wallet_success.get('account_number'))\n",
        "                  except AttributeError:\n",
        "                    account_number_col.append(None)\n",
        "                  try:\n",
        "                    account_name_col.append(wallet_success.get('account_name'))\n",
        "                  except AttributeError:\n",
        "                    account_name_col.append(None)\n",
        "                  try:\n",
        "                    bvn_col.append(wallet_success.get('bvn'))\n",
        "                  except AttributeError:\n",
        "                    bvn_col.append(None)\n",
        "                  try:\n",
        "                    requestSuccessful_col.append(wallet_success.get('requestSuccessful'))\n",
        "                  except AttributeError:\n",
        "                    requestSuccessful_col.append(None)\n",
        "                  try:\n",
        "                    responseMessage_col.append((wallet_success.get('responseMessage')))\n",
        "                  except AttributeError:\n",
        "                    responseMessage_col.append(None)\n",
        "                  try:\n",
        "                    responseCode_col.append((wallet_success.get('responseCode')))\n",
        "                  except AttributeError:\n",
        "                    responseCode_col.append(None)\n",
        "                  for n in range(len(list_column_none_wallet_success)):\n",
        "                    list_column_none_wallet_success[n].append(None) \n",
        "\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)    \n",
        "\n",
        "  df_wallet_success['Type_Request'] = type_request_col\n",
        "  df_wallet_success['Phone_Number'] = phone_Col\n",
        "  df_wallet_success['Date'] = date_col\n",
        "  df_wallet_success['EndPoint'] = endpoint_Col\n",
        "  df_wallet_success['Log_Level'] = log_level_col\n",
        "  df_wallet_success['Email'] = email_col\n",
        "  df_wallet_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_wallet_success['Total Sent'] = totalsent_col\n",
        "  df_wallet_success['Cost'] = cost_col\n",
        "  df_wallet_success['Status'] = status_col\n",
        "  df_wallet_success['Account Number'] = account_number_col\n",
        "  df_wallet_success['Account Name'] = account_name_col\n",
        "  df_wallet_success['BVN'] = bvn_col\n",
        "  df_wallet_success['Request Successful'] = requestSuccessful_col\n",
        "  df_wallet_success['Response Message'] = responseMessage_col\n",
        "  df_wallet_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_wallet_success\n",
        "             "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVPZi-uGMbDU"
      },
      "source": [
        "df_wallet_success_ = df_raw[df_raw['text'].str.contains('WALLET SUCCESS')]\n",
        "resutat_df_wallet_success = parse_row_wallet_success_function(df_wallet_success_)\n",
        "resutat_df_wallet_success.head()\n",
        "#resutat_df_wallet_success.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4IzATOC-s2M"
      },
      "source": [
        "okra = parse_wallet_sms_payload_success(df_raw['text'][0])\n",
        "print(okra.get('authorization').get('customer '))\n",
        "print(okra.get('authorization').get('env '))\n",
        "print(okra.get('authorization').get('owner '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mps5LhixM8Zo"
      },
      "source": [
        "### Handle DataFrame for OKRA WEBHOOK Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUDyIGEM8yc"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_okra_webhook_function(df_okra):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "  accountId_col = []\n",
        "  authorization_v_col = []\n",
        "  authorization_id_col = []\n",
        "  authorization_customer_col = []\n",
        "  authorization_account_col = []\n",
        "  authorization_account_id_col = []\n",
        "  authorization_account_manual_col = []\n",
        "  authorization_account_name_col = []\n",
        "  authorization_account_nuban_col = []\n",
        "  authorization_account_bank_col = []\n",
        "  authorization_account_created_at_col = []\n",
        "  authorization_account_last_updated_col = []\n",
        "  authorization_account_balance_col = []\n",
        "  authorization_account_customer_col = []\n",
        "  authorization_account_type_col = []\n",
        "  authorization_account_currency_col = []\n",
        "  authorization_accounts_col = []\n",
        "  authorization_amount_col = []\n",
        "  authorization_bank_col = []\n",
        "  authorization_created_at_col = []\n",
        "  authorization_currency_col = []\n",
        "  authorization_customerDetails_col = []\n",
        "  authorization_disconnect_col = []\n",
        "  authorization_disconnected_at_col = []\n",
        "  authorization_duration_col = []\n",
        "  authorization_env_col = []\n",
        "  authorization_garnish_col = []\n",
        "  authorization_initialAmount_col = []\n",
        "  authorization_initiated_col = []\n",
        "  authorization_last_updated_col = []\n",
        "  authorization_link_col = []\n",
        "  authorization_next_payment_col = []\n",
        "  authorization_owner_col = []\n",
        "  authorization_payLink_col = []\n",
        "  authorization_type_col = []\n",
        "  authorization_used_col = []\n",
        "  authorizationId_col = []\n",
        "  bankId_col = []\n",
        "  bankName_col = []\n",
        "  bankSlug_col = []\n",
        "  bankType_col = []\n",
        "  callbackURL_col = []\n",
        "  callback_code_col = []\n",
        "  callback_type_col = []\n",
        "  callback_url_col = []\n",
        "  code_col = []\n",
        "  country_col = []\n",
        "  current_project_col = []\n",
        "  customerEmail_col = []\n",
        "  customerId_col = []\n",
        "  ended_at_col = []\n",
        "  env_col = []\n",
        "  extras_col = []\n",
        "  identityType_col = []\n",
        "  login_type_col = []\n",
        "  message_col = []\n",
        "  meta_col = []\n",
        "  method_col = []\n",
        "  options_col = []\n",
        "  owner_col = []\n",
        "  record_col = []\n",
        "  recordId_col = []\n",
        "  started_at_col = []\n",
        "  status_webhook_col = []\n",
        "  token_col = []\n",
        "  type_col = []\n",
        "\n",
        "  list_column_none_okra_webhook = []\n",
        "  list_column_none_okra_webhook = [api_request_col, account_number_col, account_name_col, totalsent_col, \n",
        "                                   message_sms_payload_col, cost_col, status_col, responseCode_col,\n",
        "                                   bvn_col, requestSuccessful_col, responseMessage_col, email_col, phone_Col, \n",
        "                                   endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_okra.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('OKRA WEBHOOK', str_text):\n",
        "                  type_of_request = re.search('OKRA WEBHOOK', str_text)\n",
        "                  okra_webhook = parse_wallet_sms_payload_success(str_text)                  \n",
        "                  accountId_col.append(okra_webhook.get('accountId'))\n",
        "                  authorization_v_col.append(okra_webhook.get('authorization').get('__v '))\n",
        "                  authorization_id_col.append(okra_webhook.get('authorization').get('_id '))\n",
        "                  authorization_customer_col.append(okra_webhook.get('authorization').get('customer '))\n",
        "                  authorization_account_col.append(okra_webhook.get('authorization').get('account '))\n",
        "                  authorization_account_id_col.append(okra_webhook.get('authorization').get('account ')[0].get('_id '))\n",
        "                  authorization_account_manual_col.append(okra_webhook.get('authorization').get('account ')[0].get('manual '))\n",
        "                  authorization_account_name_col.append(okra_webhook.get('authorization').get('account ')[0].get('name '))\n",
        "                  authorization_account_nuban_col.append(okra_webhook.get('authorization').get('account ')[0].get('nuban '))\n",
        "                  authorization_account_bank_col.append(okra_webhook.get('authorization').get('account ')[0].get('bank '))\n",
        "                  authorization_account_created_at_col.append(okra_webhook.get('authorization').get('account ')[0].get('created_at '))\n",
        "                  authorization_account_last_updated_col.append(okra_webhook.get('authorization').get('account ')[0].get('last_updated '))\n",
        "                  authorization_account_balance_col.append(okra_webhook.get('authorization').get('account ')[0].get('balance '))\n",
        "                  authorization_account_customer_col.append(okra_webhook.get('authorization').get('account ')[0].get('customer '))\n",
        "                  authorization_account_type_col.append(okra_webhook.get('authorization').get('account ')[0].get('type '))\n",
        "                  authorization_account_currency_col.append(okra_webhook.get('authorization').get('account ')[0].get('currency '))\n",
        "                  authorization_accounts_col.append(okra_webhook.get('authorization').get('accounts '))\n",
        "                  authorization_amount_col.append(okra_webhook.get('authorization').get('amount '))\n",
        "                  authorization_bank_col.append(okra_webhook.get('authorization').get('bank '))\n",
        "                  authorization_created_at_col.append(okra_webhook.get('authorization').get('created_at '))\n",
        "                  authorization_currency_col.append(okra_webhook.get('authorization').get('currency '))\n",
        "                  authorization_customerDetails_col.append(okra_webhook.get('authorization').get('customerDetails '))\n",
        "                  authorization_disconnect_col.append(okra_webhook.get('authorization').get('disconnect '))\n",
        "                  authorization_disconnected_at_col.append(okra_webhook.get('authorization').get('disconnected_at '))\n",
        "                  authorization_duration_col.append(okra_webhook.get('authorization').get('duration '))\n",
        "                  authorization_env_col.append(okra_webhook.get('authorization').get('env '))\n",
        "                  authorization_garnish_col.append(okra_webhook.get('authorization').get('garnish '))\n",
        "                  authorization_initialAmount_col.append(okra_webhook.get('authorization').get('initialAmount '))\n",
        "                  authorization_initiated_col.append(okra_webhook.get('authorization').get('initiated '))\n",
        "                  authorization_last_updated_col.append(okra_webhook.get('authorization').get('last_updated '))\n",
        "                  authorization_link_col.append(okra_webhook.get('authorization').get('link '))\n",
        "                  authorization_next_payment_col.append(okra_webhook.get('authorization').get('next_payment '))\n",
        "                  authorization_owner_col.append(okra_webhook.get('authorization').get('owner '))\n",
        "                  authorization_payLink_col.append(okra_webhook.get('authorization').get('payLink '))\n",
        "                  authorization_type_col.append(okra_webhook.get('authorization').get('type '))\n",
        "                  authorization_used_col.append(okra_webhook.get('authorization').get('used '))\n",
        "                  authorizationId_col.append(okra_webhook.get('authorizationId'))\n",
        "                  bankId_col.append(okra_webhook.get('bankId'))\n",
        "                  bankName_col.append(okra_webhook.get('bankName'))\n",
        "                  bankSlug_col.append(okra_webhook.get('bankSlug'))\n",
        "                  bankType_col.append(okra_webhook.get('bankType'))\n",
        "                  callbackURL_col.append(okra_webhook.get('callbackURL'))\n",
        "                  callback_code_col.append(okra_webhook.get('callback_code'))\n",
        "                  callback_type_col.append(okra_webhook.get('callback_type'))\n",
        "                  callback_url_col.append(okra_webhook.get('callback_url'))\n",
        "                  code_col.append(okra_webhook.get('code'))\n",
        "                  country_col.append(okra_webhook.get('country'))\n",
        "                  current_project_col.append(okra_webhook.get('current_project'))\n",
        "                  customerEmail_col.append(okra_webhook.get('customerEmail'))\n",
        "                  customerId_col.append(okra_webhook.get('customerId'))\n",
        "                  ended_at_col.append(okra_webhook.get('ended_at'))\n",
        "                  env_col.append(okra_webhook.get('env'))\n",
        "                  extras_col.append(okra_webhook.get('extras'))\n",
        "                  identityType_col.append(okra_webhook.get('identityType'))\n",
        "                  login_type_col.append(okra_webhook.get('login_type'))\n",
        "                  message_col.append(okra_webhook.get('message'))\n",
        "                  meta_col.append(okra_webhook.get('meta'))\n",
        "                  method_col.append(okra_webhook.get('method'))\n",
        "                  options_col.append(okra_webhook.get('options'))\n",
        "                  owner_col.append(okra_webhook.get('owner'))\n",
        "                  record_col.append(okra_webhook.get('record'))\n",
        "                  recordId_col.append(okra_webhook.get('recordId'))\n",
        "                  started_at_col.append(okra_webhook.get('started_at'))\n",
        "                  status_webhook_col.append(okra_webhook.get('status'))\n",
        "                  token_col.append(okra_webhook.get('token'))\n",
        "                  type_col.append(okra_webhook.get('type'))\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                  \n",
        "                  for n in range(len(list_column_none_okra_webhook)):\n",
        "                    list_column_none_okra_webhook[n].append(None)\n",
        "\n",
        "                     \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "       \n",
        "  df_okra['Type_Request'] = type_request_col\n",
        "  df_okra['Phone_Number'] = phone_Col\n",
        "  df_okra['Date'] = date_col\n",
        "  df_okra['EndPoint'] = endpoint_Col\n",
        "  df_okra['Log_Level'] = log_level_col\n",
        "  df_okra['Email'] = email_col\n",
        "  df_okra['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_okra['Total Sent'] = totalsent_col\n",
        "  df_okra['Cost'] = cost_col\n",
        "  df_okra['Status'] = status_col\n",
        "  df_okra['Account Number'] = account_number_col\n",
        "  df_okra['Account Name'] = account_name_col\n",
        "  df_okra['BVN'] = bvn_col\n",
        "  df_okra['Request Successful'] = requestSuccessful_col\n",
        "  df_okra['Response Message'] = responseMessage_col\n",
        "  df_okra['Response Code'] = responseCode_col\n",
        "  df_okra['Account Id'] = accountId_col\n",
        "  df_okra['Authorization_V'] = authorization_v_col\n",
        "  df_okra['Authorization_Id'] = authorization_id_col\n",
        "  df_okra['Authorization_Customer'] = authorization_customer_col\n",
        "  df_okra['Authorization_Owner'] = authorization_owner_col\n",
        "  df_okra['Authorization_Account'] = authorization_account_col\n",
        "  df_okra['Authorization_account_Id'] = authorization_account_id_col\n",
        "  df_okra['Authorization_account_manual'] = authorization_account_manual_col\n",
        "  df_okra['Authorization_account_name'] = authorization_account_name_col\n",
        "  df_okra['Authorization_account_nuban'] = authorization_account_nuban_col\n",
        "  df_okra['Authorization_account_bank'] = authorization_account_bank_col\n",
        "  df_okra['Authorization_account_created_at'] = authorization_account_created_at_col\n",
        "  df_okra['Authorization_account_last_updated'] = authorization_account_last_updated_col\n",
        "  df_okra['Authorization_account_balance'] = authorization_account_balance_col\n",
        "  df_okra['Authorization_account_customer'] = authorization_account_customer_col\n",
        "  df_okra['Authorization_account_type'] = authorization_account_type_col\n",
        "  df_okra['Authorization_account_currency'] = authorization_account_currency_col\n",
        "  df_okra['Authorization_accounts'] = authorization_accounts_col\n",
        "  df_okra['Authorization_amount'] = authorization_amount_col\n",
        "  df_okra['Authorization_bank'] = authorization_bank_col\n",
        "  df_okra['Authorization_created_at'] = authorization_created_at_col\n",
        "  df_okra['Authorization_currency'] = authorization_currency_col \n",
        "  df_okra['Authorization_customerDetails'] = authorization_customerDetails_col\n",
        "  df_okra['Authorization_disconnect'] = authorization_disconnect_col\n",
        "  df_okra['Authorization_disconnected_at'] = authorization_disconnected_at_col\n",
        "  df_okra['Authorization_duration'] = authorization_duration_col\n",
        "  df_okra['Authorization_env'] = authorization_env_col\n",
        "  df_okra['Authorization_garnish'] = authorization_garnish_col\n",
        "  df_okra['Authorization_initialAmount'] = authorization_initialAmount_col\n",
        "  df_okra['Authorization_initiated'] = authorization_initiated_col\n",
        "  df_okra['Authorization_last_updated'] = authorization_last_updated_col\n",
        "  df_okra['Authorization_link'] = authorization_link_col\n",
        "  df_okra['Authorization_next_payment'] = authorization_next_payment_col\n",
        "  df_okra['Authorization_payLink'] = authorization_payLink_col\n",
        "  df_okra['Authorization_type'] = authorization_type_col\n",
        "  df_okra['Authorization_used'] = authorization_used_col\n",
        "  df_okra['AuthorizationId'] = authorizationId_col\n",
        "  df_okra['BankId'] = bankId_col\n",
        "  df_okra['BankName'] = bankName_col\n",
        "  df_okra['bankSlug'] = bankSlug_col\n",
        "  df_okra['bankType'] = bankType_col\n",
        "  df_okra['callbackURL'] = callbackURL_col\n",
        "  df_okra['callback_code'] = callback_code_col\n",
        "  df_okra['callback_type'] = callback_type_col \n",
        "  df_okra['callback_url'] = callback_url_col\n",
        "  df_okra['code'] = code_col\n",
        "  df_okra['country'] = country_col\n",
        "  df_okra['current_project'] = current_project_col\n",
        "  df_okra['customerEmail'] = customerEmail_col\n",
        "  df_okra['customerId'] = customerId_col\n",
        "  df_okra['ended_at'] = ended_at_col\n",
        "  df_okra['env'] = env_col\n",
        "  df_okra['extras'] = extras_col\n",
        "  df_okra['identityType'] = identityType_col\n",
        "  df_okra['login_type'] = login_type_col\n",
        "  df_okra['message'] = message_col\n",
        "  df_okra['meta'] = meta_col\n",
        "  df_okra['method'] = method_col\n",
        "  df_okra['options'] = options_col\n",
        "  df_okra['owner'] = owner_col\n",
        "  df_okra['record'] = record_col \n",
        "  df_okra['recordId'] = recordId_col\n",
        "  df_okra['started_at'] = started_at_col\n",
        "  df_okra['status_webhook'] = status_webhook_col\n",
        "  df_okra['token'] = token_col\n",
        "  df_okra['type'] = type_col\n",
        " \n",
        "  return df_okra\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4ZjQeK3Z10"
      },
      "source": [
        "df_okra_webhook = df_raw[df_raw['text'].str.contains('OKRA WEBHOOK')]\n",
        "parse_row_okra_webhook_function(df_okra_webhook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWmCvYp3SXf"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPh9NrF2OND7"
      },
      "source": [
        "### Handle DataFrame for LEADWAY SUCCESS Type request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWOCepv9ONYw"
      },
      "source": [
        "import re\n",
        "import regex\n",
        "import json\n",
        "\n",
        "def parse_row_leadway_function(df_leadway_success):\n",
        "  log_level_col = []\n",
        "  api_request_col = []\n",
        "  type_request_col = []\n",
        "  phone_Col = []\n",
        "  date_col = []\n",
        "  endpoint_Col = []\n",
        "  email_col = []\n",
        "  message_sms_payload_col = []\n",
        "  totalsent_col = []\n",
        "  cost_col = []\n",
        "  status_col = []\n",
        "  account_number_col = []\n",
        "  account_name_col = []\n",
        "  bvn_col = []\n",
        "  requestSuccessful_col = []\n",
        "  responseMessage_col = []\n",
        "  responseCode_col = []\n",
        "\n",
        "  list_column_none_leadway_success = []\n",
        "  list_column_none_leadway_success = [message_sms_payload_col, totalsent_col, cost_col, status_col, \n",
        "                                     account_number_col, bvn_col, requestSuccessful_col, responseMessage_col,\n",
        "                                     responseCode_col, account_name_col, email_col, phone_Col, endpoint_Col, date_col]\n",
        "  \n",
        "  list_all_colum = []\n",
        "  list_all_colum = [type_request_col, phone_Col, date_col, endpoint_Col, log_level_col, email_col, \n",
        "                    message_sms_payload_col, totalsent_col, cost_col, status_col, account_number_col,\n",
        "                    account_name_col, bvn_col, requestSuccessful_col, responseMessage_col, responseCode_col]\n",
        "\n",
        "  for index, row in df_leadway_success.iterrows():\n",
        "    str_text = row['text']\n",
        "    \n",
        "    if not str_text.startswith('['):\n",
        "      for i in range(len(list_all_colum)):\n",
        "          list_all_colum[i].append(None)\n",
        "\n",
        "    # check if the row contains \"info\" string\n",
        "    if re.search('info', str_text):\n",
        "        log_level = re.search('info', str_text)\n",
        "        try:\n",
        "          log_level_col.append(log_level.group(0))\n",
        "        except AttributeError:\n",
        "          log_level_col.append(None)             \n",
        "        if 'mailto' not in str_text:\n",
        "            if re.search('LEADWAY SUCCESS', str_text):\n",
        "                  type_of_request = re.search('LEADWAY SUCCESS', str_text)\n",
        "                  leadway_success_concat_text, index_first_succ, index_last_succ = parse_and_concatenate_Leadway_Success_Rows(df_)\n",
        "                  res_text_leadway = parse_Leadway_Success_Row(leadway_success_concat_text)\n",
        "                  for o in range(len(list_column_none_leadway_success)):\n",
        "                    list_column_none_leadway_success[o].append(None)\n",
        "\n",
        "                  try:\n",
        "                    type_request_col.append(type_of_request.group(0))\n",
        "                  except AttributeError:\n",
        "                    type_request_col.append(None)\n",
        "                   \n",
        "        elif re.search('OKRA PAYLOAD', str_text): # Nothing\n",
        "          type_of_request = re.search('OKRA PAYLOAD', str_text)\n",
        "        elif re.search('OKRA SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('OKRA SUCCESS', str_text)\n",
        "        elif re.search('VTPASS SUCCESS', str_text):   # Nothing\n",
        "          type_of_request = re.search('VTPASS SUCCESS', str_text)  \n",
        "\n",
        "  df_leadway_success['Type_Request'] = type_request_col\n",
        "  df_leadway_success['Phone_Number'] = phone_Col\n",
        "  df_leadway_success['Date'] = date_col\n",
        "  df_leadway_success['EndPoint'] = endpoint_Col\n",
        "  df_leadway_success['Log_Level'] = log_level_col\n",
        "  df_leadway_success['Email'] = email_col\n",
        "  df_leadway_success['Message SMS Payload'] = message_sms_payload_col\n",
        "  df_leadway_success['Total Sent'] = totalsent_col\n",
        "  df_leadway_success['Cost'] = cost_col\n",
        "  df_leadway_success['Status'] = status_col\n",
        "  df_leadway_success['Account Number'] = account_number_col\n",
        "  df_leadway_success['Account Name'] = account_name_col\n",
        "  df_leadway_success['BVN'] = bvn_col\n",
        "  df_leadway_success['Request Successful'] = requestSuccessful_col\n",
        "  df_leadway_success['Response Message'] = responseMessage_col\n",
        "  df_leadway_success['Response Code'] = responseCode_col\n",
        " \n",
        "  return df_leadway_success\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFTSv_Y0mcjO"
      },
      "source": [
        "### Concatenate DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-VL2Igymfck"
      },
      "source": [
        "pdList = [df_error, resutat_df_api, resutat_df_client_mobile_login, resutat_df_sms_payload, \n",
        "          resutat_df_sms_success, resutat_df_wallet_success, df_okra_webhook]  # List of our dataframes\n",
        "df_final = pd.concat(pdList)\n",
        "df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qsXB16xUGyd"
      },
      "source": [
        "### Export final Dataframe to a file csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyP128bIS8o1"
      },
      "source": [
        "df_final.to_csv('/content/drive/MyDrive/datasets/nirra_log_bot.csv', index=None)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tAOylN7OU99"
      },
      "source": [
        "### Récupérer les numéros de téléphone différents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z47mOjmAOkCM"
      },
      "source": [
        "df_final['Phone_Number'].unique() # récupérer la liste des différents numéros de téléphone\n",
        "all_users_phone_number = [element for element in df_final['Phone_Number'].unique() if element != None] # all userId\n",
        "all_users_phone_number # liste de tous les différents numéros de téléphone.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOulnkEKP-Wr"
      },
      "source": [
        "all_df_phone_number = [] # to get list of dataframes\n",
        "for phoneNumber in all_users_phone_number:\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber] # récupérer les dataframes avec seulement les numéros de téléphone\n",
        "  all_df_phone_number.append(df_phone_number)  # mettre chaque dataframe dans la\n",
        "\n",
        "all_df_phone_number[0] # print the first dataframe inside the list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_tvM7PdRSE0"
      },
      "source": [
        "### sauvegarder les dataframes sur disque "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq3drem3RRm2",
        "outputId": "c6d57011-91de-42a2-97fb-3fff5dd75409"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# tqdm permet\n",
        "for phoneNumber in tqdm(all_users_phone_number):\n",
        "  df_phone_number = df_final[df_final['Phone_Number'] == phoneNumber]\n",
        "  df_phone_number.to_csv(f'/content/drive/MyDrive/datasets/files/{phoneNumber}.csv', index=None)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:01<00:00, 98.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cct87UPHuM_7",
        "outputId": "0637ac6f-b8cb-4fab-eab1-42759d8c6bd1"
      },
      "source": [
        "cd /content/drive/MyDrive/datasets/files/"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGN3PMQmuSot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YixcW0AMuTYZ",
        "outputId": "886ef9d1-3724-48a4-d9a1-8e341d7dd01b"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# use glob to get all the csv files \n",
        "# in the folder\n",
        "path = os.getcwd()\n",
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "all_df_list = [] # list of all dataframe\n",
        "# loop over the list of csv files\n",
        "number_transactions = []\n",
        "all_df_list_with_number_transaction = []\n",
        "all_df_with_diff = []\n",
        "all_ts = []\n",
        "all_ts_diff = []\n",
        "for f in tqdm(csv_files):    \n",
        "    # read the csv file\n",
        "    df = pd.read_csv(f)  \n",
        "    all_df_list.append(df)   \n",
        "    # print the location and filename\n",
        "    #print('Location:', f)\n",
        "    #print('File Name:', f.split(\"\\\\\")[-1])\n",
        "    # print the content\n",
        "    #print('Content:')\n",
        "    #display(df)\n",
        "    #print()\n",
        "\n",
        "for element in all_df_list:\n",
        "  element['Number_Transactions'] = element.shape[0] # faire la somme des lignes et mettre dans la colonne Number_Transactions\n",
        "  all_df_list_with_number_transaction.append(element)# mettre tous les éléments dans une nouvelle liste\n",
        "\n",
        "#Faire la différence entre les timestamp\n",
        "for ele_with_num_trans in all_df_list_with_number_transaction:\n",
        "  df_ts = pd.DataFrame(ele_with_num_trans['ts'])\n",
        "  ele_with_num_trans['ts_diff'] = df_ts.diff(axis=0)\n",
        "  all_df_with_diff.append(ele_with_num_trans)\n",
        "\n",
        "# Faire des plots pour chaque utilisateur\n",
        "for ele_plot in all_df_with_diff:\n",
        "  attributes = [\"Number_Transactions\", \"ts_diff\"]\n",
        "  #scatter_matrix(ele_plot[attributes], figsize=(10, 5))\n",
        "  #plt.show()\n",
        "\n",
        "new_endpoint_col = []\n",
        "count_payment = 0\n",
        "count_decline = 0\n",
        "all_df_with_number = []\n",
        "for element_endpoint in all_df_with_diff:\n",
        "  new_endpoint_col = element_endpoint['EndPoint']\n",
        "  for end in new_endpoint_col:\n",
        "    if re.search('payment', str(end)):\n",
        "      count_payment +=1\n",
        "    elif re.search('decline', str(end)):\n",
        "      count_decline +=1\n",
        "  element_endpoint['Number_payment'] = count_payment\n",
        "  element_endpoint['Number_decline'] = count_decline\n",
        "  all_df_with_number.append(element_endpoint)\n",
        "  count_payment = 0\n",
        "  count_decline = 0\n",
        "    "
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112/112 [00:00<00:00, 118.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxF2xJfhUeo",
        "outputId": "48b294ee-dade-4c9b-8511-09ed83112c9e"
      },
      "source": [
        "cd /content/drive/My Drive/datasets/new_files"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/datasets/new_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qebtQVU8k2hr"
      },
      "source": [
        "### Sauvegarder les nouveaux datasets dans un nouveau dossier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXcimjuqS7ya",
        "outputId": "4fe2e839-4d05-409e-ba36-0c1b9371c88d"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# tqdm permet\n",
        "for elem in tqdm(all_df_with_number):\n",
        "  phone = elem['Phone_Number'][0]\n",
        "  elem.to_csv(f'/content/drive/MyDrive/datasets/new_files/{phone}.csv', index=None)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112/112 [00:01<00:00, 67.31it/s]\n"
          ]
        }
      ]
    }
  ]
}